<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Theses on ninjaduck</title>
    <link>http://www.ninjaducks.in/thesis/</link>
    <description>Recent content in Theses on ninjaduck</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://www.ninjaducks.in/thesis/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Acknowledgements</title>
      <link>http://www.ninjaducks.in/thesis/mainli1.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainli1.html</guid>
      <description>
&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainli2.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;#tailmainli1.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainli1.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;h2 class=&#34;likechapterHead&#34;&gt;&lt;a
href=&#34;main.html#QQ2-2-1&#34; id=&#34;x2-1000&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/h2&gt;  I would like to extend my sincere gratitude towards my thesis
supervisors, Prof. Mainak Chaudhuri and Prof. Sumit Ganguly for their guidance,
constant support and encouragement. This thesis would not have been possible without
them.
&lt;p&gt;I thank the Department of Computer Science and Engineering, IIT Kanpur for providing
the necessary infrastructure and congenial environment facilitating this research
work.
&lt;/p&gt;
&lt;p&gt;   I also thank Tejas Gandhi for providing invaluable help in setting up Openstack,
Adarsh Jagannath for various useful discussions we had which proved instrumental in the
progress of this thesis, Abhimanyu Arora for working on a part of this thesis together
with me, and all my fellow batchmates for the delightful time we spent together and
making my stay at IITK memorable.
&lt;/p&gt;
&lt;p&gt;   I am forever indebted to my family for everything in my life.
&lt;/p&gt;
&lt;p&gt;                                                                      &lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Shivanshu&lt;/span&gt;
&lt;span
class=&#34;cmbx-12&#34;&gt;Agrawal&lt;/span&gt;&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;




&lt;/p&gt;
&lt;!--l. 91--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainli2.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainli1.html&#34; &gt;front&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainli1.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;   &lt;a
id=&#34;tailmainli1.html&#34;&gt;&lt;/a&gt;&lt;/p&gt;



</description>
    </item>
    
    <item>
      <title>Architecture and Design of DRS</title>
      <link>http://www.ninjaducks.in/thesis/mainch3.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainch3.html</guid>
      <description>
&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch4.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainch2.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch2.html#tailmainch2.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;#tailmainch3.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch3.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;h2 class=&#34;chapterHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;Chapter 3&lt;/span&gt;&lt;br /&gt;&lt;a
href=&#34;main.html#QQ2-8-35&#34; id=&#34;x8-310003&#34;&gt;Architecture and Design of DRS&lt;/a&gt;&lt;/h2&gt;
&lt;a
id=&#34;x8-31001r32&#34;&gt;&lt;/a&gt;
&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;3.1   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-8-36&#34; id=&#34;x8-320001&#34;&gt;Functions of DRS&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Distributed resource scheduler is responsible for handling the dynamic resource allocation
requirements of VMs on the cloud. The job of a DRS can be divided into three
categories:
   &lt;/p&gt;
&lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
1. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Monitoring.&lt;/span&gt;&lt;/strong&gt; Monitoring is essential for detecting the resource requirements
   of individual guest machines running on the cloud and detecting hotspots on
   physical hosts which make up the cluster. It has to be ﬁne-grained enough to
   detect changes in the load proﬁle of the hosts and guests. It has to be coarse
   enough to ﬁlter short-terms changes in the resource requirements of the guests.
   It will also regularly update the load statistics of the host in a shared data
   store which can be used to get a global account of the cluster state at any
   point of time which will be useful in making decisions about live-migration.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
2. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Memory Management.&lt;/span&gt;&lt;/strong&gt; For all the guests running on the same host, DRS
   will  manage  their  ever  changing  memory  demands.  Autoballooning  is  an
   essential technique for the DRS to perform this aspect of its functionality. This
   part of DRS will look at the memory usage statistics of all the guests, ﬁgure
   out which VMs need more memory and which VMs have idle memory, and try
   to meet the demands of each VM by inﬂating/deﬂating its balloon.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
3. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Hotspot Mitigation.&lt;/span&gt;&lt;/strong&gt; In the case of a hotspot, this part of DRS is responsible
   for selecting an appropriate guest to migrate and the best destination for it
   based on the resource usage data of all the machines present in the cluster.&lt;/dd&gt;&lt;/dl&gt;


&lt;a
id=&#34;x8-32004r36&#34;&gt;&lt;/a&gt;
&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;3.2   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-8-37&#34; id=&#34;x8-330002&#34;&gt;Goals and Non-Goals&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Goal:&lt;/span&gt;&lt;/em&gt; Develop a DRS for private clouds which makes the best use of the resources
available i.e. provides the resources to the machines on a best eﬀort basis according to the
priority/importance of each VM. If the cluster is not fully loaded, the demands of all the
VMs can be satisﬁed but if the load is more than the capacity, the VMs will have
to do with less resources than promised. In case of an overload, all the VMs
with the same priority across the cluster should be treated equally in resource
allocation.
&lt;/p&gt;
&lt;p&gt;   &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Goal:&lt;/span&gt;&lt;/em&gt; The DRS design should be decentralized so that it is easily able to scale up to a
cluster having thousands of physical hosts and there is no single point of failure in the
system.
&lt;/p&gt;
&lt;p&gt;   &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Non-goal:&lt;/span&gt;&lt;/em&gt; Minimizing the number of machines used. Though using less machines
will save power because the unused machines can be turned oﬀ, the goals of
power management are orthogonal to the goals of our DRS and can be treated
separately.
&lt;/p&gt;
&lt;p&gt;   &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Non-goal:&lt;/span&gt;&lt;/em&gt; For the purpose of this thesis, we have considered balancing only memory
and CPU resources. Other resources like disk I/O, and network bandwidth have not been
taken into account.
&lt;a
id=&#34;x8-33001r37&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;3.3   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-8-38&#34; id=&#34;x8-340003&#34;&gt;Architecture Overview&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The DRS architecture described below is fully decentralized, which is a key requirement
for scaling it up to thousands of hosts. Decentralization also prevents any single point of
failures. Each host in the cluster makes its own decision about the guest machines on that
host and the other hosts co-operate with it to make that decision successful. The DRS is
divided into three components based on the three types of job mentioned earlier that it
has to perform.


&lt;/p&gt;
&lt;hr class=&#34;figure&#34; /&gt;&lt;div class=&#34;figure&#34;
&gt;


&lt;a
id=&#34;x8-34001r1&#34;&gt;&lt;/a&gt;



&lt;p&gt;&lt;img
src=&#34;/images/thesis/arch.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x8-34002&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;/p&gt;
&lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 3.1: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Architecture of the DRS&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x8-34001r3 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfigure&#34; /&gt;
&lt;a
id=&#34;x8-34003r31&#34;&gt;&lt;/a&gt;
&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;3.3.1   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-8-39&#34; id=&#34;x8-350001&#34;&gt;The Monitoring Service&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;A &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;monitoring service&lt;/span&gt;&lt;/em&gt; runs on all the hosts of the cluster. On each host, it collects the
resource usage statistics of all the VMs on the host and the total resource usage of the
host. It also ﬁlters out the short-term changes in the resource usage and ﬁgures
out the changes in the load proﬁle. It also detects any hotspot and triggers the
migration service to perform its task of migrating a guest away from the host. The
service also accommodates (start monitoring) any new guest that is migrated to a
host.
&lt;/p&gt;
&lt;p&gt;   The service talks to a distributed key-value store to regularly update the resource
usage statistics of the host it is running on. The key-value store should be updated only
when there is a signiﬁcant change in the resource usage proﬁles of the host, which could
aﬀect the decision making of live migration. Small changes in the resource usage are
unnecessary to track as they will not aﬀect the decision making. Short-term spikes in the
resource usage can adversely aﬀect the live-migration decisions by misrepresenting the
resource usage.
&lt;a
id=&#34;x8-35001r39&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;3.3.2   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-8-40&#34; id=&#34;x8-360002&#34;&gt;The Memory Balancing Service&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;A &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;memory balancing Service&lt;/span&gt;&lt;/em&gt; runs on all the hosts. On each host, the service looks at the
memory usage statistics of all the VMs running on the host provided by the monitoring
service. It ﬁgures out which hosts require more memory and which hosts have some idle
memory. It then balances the memory by inﬂating/deﬂating the balloons of the
VMs.
&lt;/p&gt;
&lt;p&gt;   If the demands of all the VMs can be satisﬁed, balancing takes idle memory and gives
it to the needy. If the demands of all the VMs cannot be satisﬁed i.e. there is a hotspot on
the host, the service calculates the entitled memory based on the priority of each


VM running on the host for each guest. Entitled memory may be less than the
memory needs of a guest. Then the service distributes memory according to the
entitlement.
&lt;/p&gt;
&lt;p&gt;   The service also tries to make space by freeing memory for any new guest that is to
be migrated to the host. Notably, this service does not do anything to resolve
hotspots. It just tries to balance memory amongst the guests present on the
host. Hotspot mitigation is left to the migration service. If there is a hotspot,
some guest(s) may get migrated out of the host, leaving free memory for other
VMs.
&lt;/p&gt;
&lt;p&gt;   The memory management requires a separate service while CPU management does
not. There are two reasons for this.
   &lt;/p&gt;
&lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
1. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;vCPU of each VM is handled as a thread by the hypervisor and hence scheduled
   according to its process scheduling policy, while there is no such system for
   memory.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
2. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;Memory,  once  consumed  by  a  VM,  is  not  reclaimed  automatically  by  the
   hypervisor, while this is not the case with the CPU resources. Each vCPU
   thread gets a time slice to run which is decided by the hypervisor and the
   CPU is taken away from the thread after the time slice ends.
   &lt;/dd&gt;&lt;/dl&gt;
&lt;a
id=&#34;x8-36003r40&#34;&gt;&lt;/a&gt;
&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;3.3.3   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-8-41&#34; id=&#34;x8-370003&#34;&gt;The Migration Service&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;This service runs on all the hosts and is triggered by the &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;monitoring service&lt;/span&gt;&lt;/em&gt; when there is
a hotspot on the host. It collects the resource usage statistics of all the other hosts in the
cluster from the data-store to which the monitoring services of all the hosts
write. This data would be just a few key-value pairs per host and hence, very
small. Using this data (and some other), it tries to ﬁnd out the best migration


(guest VM-destination host pair) performing which will improve some metric
representing the resource requirement satisfaction or the overall performance
of the VMs on the cluster. The service talks to the memory balancing service
on the destination host to free required memory for the incoming guest, and
then it migrates the guest to the destination. The migration service requires
resource usage details of the entire cluster to make an informed decision on
migration.
&lt;a
id=&#34;Q1-8-42&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;likesubsectionHead&#34;&gt;&lt;a
href=&#34;#x8-380003&#34; id=&#34;x8-380003&#34;&gt;Summary&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;In this chapter, we have discussed the functions and goals of a DRS. We have also
proposed a decentralized architecture for DRS which can scale well and is free of single
point failures.


&lt;/p&gt;
&lt;!--l. 1--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch4.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainch2.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch2.html#tailmainch2.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;mainch3.html&#34; &gt;front&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch3.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;   &lt;a
id=&#34;tailmainch3.html&#34;&gt;&lt;/a&gt;        &lt;/p&gt;


</description>
    </item>
    
    <item>
      <title>Conclusions</title>
      <link>http://www.ninjaducks.in/thesis/mainch6.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainch6.html</guid>
      <description>
&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainli5.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainch5.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch5.html#tailmainch5.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;#tailmainch6.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch6.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;h2 class=&#34;chapterHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;Chapter 6&lt;/span&gt;&lt;br /&gt;&lt;a
href=&#34;main.html#QQ2-10-62&#34; id=&#34;x11-600006&#34;&gt;Conclusions&lt;/a&gt;&lt;/h2&gt;
&lt;a
id=&#34;x11-60001r60&#34;&gt;&lt;/a&gt;
&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;6.1   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-10-63&#34; id=&#34;x11-610001&#34;&gt;Summary&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Resource overcommitment is an essential technique for eﬃcient use of resources in a cloud
infrastructure. There are several hurdles in overcommitment which have not been
addressed completely yet. Most of the studies in this ﬁeld focus on just a part of the
problem, but do not solve it as a whole. The subproblems that have attracted most
attention is the optimal placement of virtual machines depending on their demands. But
many of these studies do not take the dynamic nature of resource demand of the VMs or
the performance degradation during live migration into account. Through this thesis, we
have tried to solve this problem by taking the whole picture into account, and not just a
part of it.
&lt;/p&gt;
&lt;p&gt;   In this thesis, we have identiﬁed some of the major problems faced in overcommitment
of CPU and memory resources in a virtualized environment. We have described some of
the relevant work done in this area and their limitations. We have proposed an approach
and architecture to build a decentralized distributed resource scheduler to manage the
cloud resources under overcommitment. The DRS is designed to be horizontally scalable
and has no single point of failure. We have also implemented a complete DRS system for
QEMU-KVM virtualization platform. The implementation of the autoballooning and
monitoring component have been described in detail and their performance has been
analyzed by experimentation.
&lt;/p&gt;
&lt;p&gt;   Our implementation is open-source and the code for it can be found here:
&lt;/p&gt;

&lt;div class=&#34;center&#34;
&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a
href=&#34;https://github.com/shivanshuag/thesis-code&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;https://github.com/shivanshuag/thesis-code&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;


&lt;a
id=&#34;x11-61001r68&#34;&gt;&lt;/a&gt;
&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;6.2   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-10-64&#34; id=&#34;x11-620002&#34;&gt;Future Work&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Although we have demonstrated that our technique for autoballooning is eﬃcient, there
are still some limitations to this approach which need to be addressed.
&lt;a
id=&#34;x11-62001r64&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;6.2.1   &lt;/span&gt; &lt;a
href=&#34;#x11-630001&#34; id=&#34;x11-630001&#34;&gt;Limitation of Memory Ballooning&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The balloon driver is used to modify the amount of memory a VM has. This might have
some unintended aﬀects on the processes running inside the VM. A new process starting
on the guest may require more memory than is present(because some amount of memory
has been ballooned out) and crash if it does not get that memory. In some cases, if no
available memory is left inside the guest, and the guest does not have swap space, the
Linux OOM killer may be activated to kill some of the processes and reclaim memory.
This is a rare situation and requires that either there is no swap device, or swap memory
is exhausted.
&lt;/p&gt;
&lt;p&gt;   Ideally, the memory ballooning process should be totally transparent to the guest VM.
Doing this is a non-trivial task which might require exposing the memory allocation
requests inside the guest VM to the host.
&lt;a
id=&#34;x11-63001r70&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;6.2.2   &lt;/span&gt; &lt;a
href=&#34;#x11-640002&#34; id=&#34;x11-640002&#34;&gt;Supporting More Resource Types&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The DRS we have built right now supports balancing of only CPU and memory resources.
Other resources like the network bandwidth and disk i/o can also be overcommited and
can be taken into account for balancing and migration.
&lt;a
id=&#34;x11-64001r71&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;6.2.3   &lt;/span&gt; &lt;a
href=&#34;#x11-650003&#34; id=&#34;x11-650003&#34;&gt;Multiple Migrations&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;In our DRS, the migration service considers only single migrations to resolve


hotspots. Sometimes, multiple migrations may be required to resolve a single
hotspot. This will involve coordination between more than two machines for
migration. Strategies to make this process eﬀective and beneﬁcial need to be
explored.


&lt;/p&gt;
&lt;p&gt;




&lt;/p&gt;
&lt;!--l. 123--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainli5.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainch5.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch5.html#tailmainch5.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;mainch6.html&#34; &gt;front&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch6.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;   &lt;a
id=&#34;tailmainch6.html&#34;&gt;&lt;/a&gt;      &lt;/p&gt;


</description>
    </item>
    
    <item>
      <title>Contents</title>
      <link>http://www.ninjaducks.in/thesis/mainli2.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainli2.html</guid>
      <description>
&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainli3.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainli1.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainli1.html#tailmainli1.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;#tailmainli2.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainli2.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;h2 class=&#34;likechapterHead&#34;&gt;&lt;a
href=&#34;main.html#QQ2-3-2&#34; id=&#34;x3-2000&#34;&gt;Contents&lt;/a&gt;&lt;/h2&gt; &lt;div class=&#34;tableofcontents&#34;&gt;
&lt;span class=&#34;chapterToc&#34; &gt;1 &lt;a
href=&#34;mainch1.html#x6-50001&#34;&gt;Introduction: Virtualization and Resource Management in Cloud&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;1.1 &lt;a
href=&#34;mainch1.html#x6-60001&#34;&gt;Virtualization&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;1.1.1 &lt;a
href=&#34;mainch1.html#x6-70001&#34; id=&#34;QQ2-6-9&#34;&gt;Memory Overcommitment and Ballooning&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;1.1.2 &lt;a
href=&#34;mainch1.html#x6-80002&#34; id=&#34;QQ2-6-10&#34;&gt;CPU Overcommitment&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;1.2 &lt;a
href=&#34;mainch1.html#x6-90002&#34;&gt;Virtual Machine Live Migration&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;1.3 &lt;a
href=&#34;mainch1.html#x6-100003&#34;&gt;Resource Management in Cloud&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;1.4 &lt;a
href=&#34;mainch1.html#x6-110004&#34;&gt;Organization of this Thesis &lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;chapterToc&#34; &gt;2 &lt;a
href=&#34;mainch2.html#x7-130002&#34;&gt;Related Work&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;2.1 &lt;a
href=&#34;mainch2.html#x7-140001&#34;&gt;Auto-Ballooning in Xen&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;2.1.1 &lt;a
href=&#34;mainch2.html#x7-150001&#34; id=&#34;QQ2-7-18&#34;&gt;Transcendent Memory (tmem)&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;2.1.2 &lt;a
href=&#34;mainch2.html#x7-190002&#34; id=&#34;QQ2-7-22&#34;&gt;Auto-Balloon Mechanism&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;2.2 &lt;a
href=&#34;mainch2.html#x7-200002&#34;&gt;Memory Management in VMware ESX&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;2.2.1 &lt;a
href=&#34;mainch2.html#x7-210001&#34; id=&#34;QQ2-7-24&#34;&gt;Memory Reclamation Techniques&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;2.2.2 &lt;a
href=&#34;mainch2.html#x7-220002&#34; id=&#34;QQ2-7-25&#34;&gt;Memory Reclamation Policies&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;2.3 &lt;a
href=&#34;mainch2.html#x7-250003&#34;&gt;VMware Distributed Resource Management&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;2.3.1 &lt;a
href=&#34;mainch2.html#x7-260001&#34; id=&#34;QQ2-7-29&#34;&gt;Resource Model&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;2.3.2 &lt;a
href=&#34;mainch2.html#x7-270002&#34; id=&#34;QQ2-7-30&#34;&gt;DRS Algorithm&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;2.3.3 &lt;a
href=&#34;mainch2.html#x7-280003&#34; id=&#34;QQ2-7-31&#34;&gt;Limitations of VMware DRS&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;2.4 &lt;a
href=&#34;mainch2.html#x7-290004&#34;&gt;Other Works&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;chapterToc&#34; &gt;3 &lt;a
href=&#34;mainch3.html#x8-310003&#34;&gt;Architecture and Design of DRS&lt;/a&gt;&lt;/span&gt;


&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;3.1 &lt;a
href=&#34;mainch3.html#x8-320001&#34;&gt;Functions of DRS&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;3.2 &lt;a
href=&#34;mainch3.html#x8-330002&#34;&gt;Goals and Non-Goals&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;3.3 &lt;a
href=&#34;mainch3.html#x8-340003&#34;&gt;Architecture Overview&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;3.3.1 &lt;a
href=&#34;mainch3.html#x8-350001&#34; id=&#34;QQ2-8-39&#34;&gt;The Monitoring Service&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;3.3.2 &lt;a
href=&#34;mainch3.html#x8-360002&#34; id=&#34;QQ2-8-40&#34;&gt;The Memory Balancing Service&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;3.3.3 &lt;a
href=&#34;mainch3.html#x8-370003&#34; id=&#34;QQ2-8-41&#34;&gt;The Migration Service&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;chapterToc&#34; &gt;4 &lt;a
href=&#34;mainch4.html#x9-390004&#34;&gt;Implementation of Monitoring and Auto-Ballooning&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;4.1 &lt;a
href=&#34;mainch4.html#x9-400001&#34;&gt;Monitoring&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;4.1.1 &lt;a
href=&#34;mainch4.html#x9-410001&#34; id=&#34;QQ2-9-46&#34;&gt;Host Monitoring&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;4.1.2 &lt;a
href=&#34;mainch4.html#x9-440002&#34; id=&#34;QQ2-9-49&#34;&gt;Guest Monitoring&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;4.1.3 &lt;a
href=&#34;mainch4.html#x9-470003&#34; id=&#34;QQ2-9-52&#34;&gt;Hotspot Detection and Key-Value Store Updation&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;4.2 &lt;a
href=&#34;mainch4.html#x9-480002&#34;&gt;Auto-Ballooning&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;4.2.1 &lt;a
href=&#34;mainch4.html#x9-490001&#34; id=&#34;QQ2-9-54&#34;&gt;Hard Ballooning and Soft Ballooning&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;4.2.2 &lt;a
href=&#34;mainch4.html#x9-500002&#34; id=&#34;QQ2-9-55&#34;&gt;Auto-Ballooning Algorithm&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;chapterToc&#34; &gt;5 &lt;a
href=&#34;mainch5.html#x10-520005&#34;&gt;Experimental Evaluation&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;5.1 &lt;a
href=&#34;mainch5.html#x10-530001&#34;&gt;Experimental Setup&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;5.2 &lt;a
href=&#34;mainch5.html#x10-540002&#34;&gt;Results&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;5.2.1 &lt;a
href=&#34;mainch5.html#x10-550001&#34; id=&#34;QQ2-10-61&#34;&gt;Analyzing Auto-Ballooning&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;5.2.2 &lt;a
href=&#34;mainch5.html#x10-560002&#34; id=&#34;QQ2-10-62&#34;&gt;Analyzing CPU Hotspot Detection&lt;/a&gt;&lt;/span&gt;

&lt;br /&gt;
&lt;span class=&#34;chapterToc&#34; &gt;6 &lt;a
href=&#34;mainch6.html#x11-600006&#34; id=&#34;QQ2-10-63&#34;&gt;Conclusions&lt;/a&gt;&lt;/span&gt;

&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;6.1 &lt;a
href=&#34;mainch6.html#x11-610001&#34; id=&#34;QQ2-10-64&#34;&gt;Summary&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;6.2 &lt;a
href=&#34;mainch6.html#x11-620002&#34; id=&#34;QQ2-10-65&#34;&gt;Future Work&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;6.2.1 &lt;a
href=&#34;mainch6.html#x11-630001&#34; id=&#34;QQ2-10-66&#34;&gt;Limitation of Memory Ballooning&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;6.2.2 &lt;a
href=&#34;mainch6.html#x11-640002&#34; id=&#34;QQ2-10-67&#34;&gt;Supporting More Resource Types&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;     &lt;span class=&#34;subsectionToc&#34; &gt;6.2.3 &lt;a
href=&#34;mainch6.html#x11-650003&#34; id=&#34;QQ2-10-68&#34;&gt;Multiple Migrations&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;
&lt;span class=&#34;likechapterToc&#34; &gt;&lt;a
href=&#34;mainli5.html#x12-660003&#34; id=&#34;QQ2-2-69&#34;&gt;References&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;


&lt;/div&gt;


&lt;!--l. 92--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainli3.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainli1.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainli1.html#tailmainli1.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;mainli2.html&#34; &gt;front&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainli2.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;   &lt;a
id=&#34;tailmainli2.html&#34;&gt;&lt;/a&gt; &lt;/p&gt;


</description>
    </item>
    
    <item>
      <title>Distributed Memory and CPU Management in Cloud Computing Environments</title>
      <link>http://www.ninjaducks.in/thesis/main.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/main.html</guid>
      <description>

&lt;div class=&#34;maketitle&#34;&gt;


&lt;br /&gt;
&lt;h2 class=&#34;titleHead&#34;&gt;Distributed Memory and CPU Management in
Cloud Computing Environments&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;
&lt;em&gt;&lt;span
class=&#34;cmti-12x-x-120&#34;&gt;A thesis&lt;/span&gt;&lt;span
class=&#34;cmti-12x-x-120&#34;&gt; submitted&lt;/span&gt;&lt;/em&gt;&lt;br /&gt;
&lt;span
class=&#34;cmr-12x-x-120&#34;&gt;in Partial Fulﬁllment of the Requirements&lt;/span&gt;&lt;br /&gt;
&lt;span
class=&#34;cmr-12x-x-120&#34;&gt;for the Degree of&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;
&lt;span
class=&#34;cmr-12x-x-120&#34;&gt;Master of Technology&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;
&lt;span
class=&#34;cmr-12x-x-120&#34;&gt;by&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;
&lt;div class=&#34;author&#34; &gt;&lt;span
class=&#34;cmbx-12x-x-120&#34;&gt;Shivanshu Agrawal&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;
&lt;em&gt;&lt;span
class=&#34;cmti-12x-x-120&#34;&gt;to the&lt;/span&gt;&lt;/em&gt;&lt;br /&gt;
&lt;span
class=&#34;cmr-12x-x-120&#34;&gt;DEPARTMENT OF COMPUTER SCIENCE &amp;#x0026; ENGINEERING&lt;/span&gt;&lt;br /&gt;
&lt;span
class=&#34;cmr-12x-x-120&#34;&gt;INDIAN INSTITUTE OF TECHNOLOGY KANPUR&lt;/span&gt;&lt;br /&gt;
&lt;div class=&#34;date&#34; &gt;&lt;span
class=&#34;cmr-12x-x-120&#34;&gt;May, 2016&lt;/span&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;div
class=&#34;abstract&#34;
&gt;


&lt;div class=&#34;center&#34;
&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;&lt;span
class=&#34;cmbx-12x-x-120&#34;&gt;ABSTRACT&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;To eﬃciently utilize the resources in a virtualized environment, they need to be
overcommited. Overcommitment is the process of allocating more resources to a virtual
machine, or a group of virtual machines than are physically present on the host. It is
based on the premise that most of the Virtual Machines will use only a small percentage
of the resources allocated to them at a given time. However, situations may arise when
the resources required by the virtual machines are more than the physical resources
present on the machine. The performance of the Virtual Machines will be severely
impacted in these situations. Most cloud providers generally have Service Level
Agreements (SLAs) with their clients and hence cannot allow virtual machines to deliver
a poor quality of service.
&lt;/p&gt;
&lt;p&gt;   In this thesis, we explore the problem of overcommitment of the CPU and memory
resources. We propose a distributed resource scheduler (DRS) which uses techniques such
as memory ballooning and virtual machine live nigration to solve the problems in CPU
and memory overcommitment. We design an architecture for DRS which is horizontally
scalable and describe the techniques involved in monitoring and memory ballooning
aspects of the DRS.


&lt;/p&gt;
&lt;/div&gt;


&lt;div class=&#34;tableofcontents&#34;&gt;
&lt;span class=&#34;likechapterToc&#34; &gt;&lt;a
href=&#34;mainli1.html#x2-1000&#34; id=&#34;QQ2-2-1&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;likechapterToc&#34; &gt;&lt;a
href=&#34;mainli2.html#x3-2000&#34; id=&#34;QQ2-3-2&#34;&gt;Contents&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;  &lt;span class=&#34;chapterToc&#34; &gt;1 &lt;a
href=&#34;mainch1.html#x6-50001&#34; id=&#34;QQ2-6-7&#34;&gt;Introduction: Virtualization and Resource Management in Cloud&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;1.1 &lt;a
href=&#34;mainch1.html#x6-60001&#34; id=&#34;QQ2-6-8&#34;&gt;Virtualization&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;1.2 &lt;a
href=&#34;mainch1.html#x6-90002&#34; id=&#34;QQ2-6-11&#34;&gt;Virtual Machine Live Migration&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;1.3 &lt;a
href=&#34;mainch1.html#x6-100003&#34; id=&#34;QQ2-6-12&#34;&gt;Resource Management in Cloud&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;1.4 &lt;a
href=&#34;mainch1.html#x6-110004&#34; id=&#34;QQ2-6-13&#34;&gt;Organization of this Thesis &lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;chapterToc&#34; &gt;2 &lt;a
href=&#34;mainch2.html#x7-130002&#34; id=&#34;QQ2-7-16&#34;&gt;Related Work&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;2.1 &lt;a
href=&#34;mainch2.html#x7-140001&#34; id=&#34;QQ2-7-17&#34;&gt;Auto-Ballooning in Xen&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;2.2 &lt;a
href=&#34;mainch2.html#x7-200002&#34; id=&#34;QQ2-7-23&#34;&gt;Memory Management in VMware ESX&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;2.3 &lt;a
href=&#34;mainch2.html#x7-250003&#34; id=&#34;QQ2-7-28&#34;&gt;VMware Distributed Resource Management&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;2.4 &lt;a
href=&#34;mainch2.html#x7-290004&#34; id=&#34;QQ2-7-32&#34;&gt;Other Works&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;chapterToc&#34; &gt;3 &lt;a
href=&#34;mainch3.html#x8-310003&#34; id=&#34;QQ2-8-35&#34;&gt;Architecture and Design of DRS&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;3.1 &lt;a
href=&#34;mainch3.html#x8-320001&#34; id=&#34;QQ2-8-36&#34;&gt;Functions of DRS&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;3.2 &lt;a
href=&#34;mainch3.html#x8-330002&#34; id=&#34;QQ2-8-37&#34;&gt;Goals and Non-Goals&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;3.3 &lt;a
href=&#34;mainch3.html#x8-340003&#34; id=&#34;QQ2-8-38&#34;&gt;Architecture Overview&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;chapterToc&#34; &gt;4 &lt;a
href=&#34;mainch4.html#x9-390004&#34; id=&#34;QQ2-9-44&#34;&gt;Implementation of Monitoring and Auto-Ballooning&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;4.1 &lt;a
href=&#34;mainch4.html#x9-400001&#34; id=&#34;QQ2-9-45&#34;&gt;Monitoring&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;4.2 &lt;a
href=&#34;mainch4.html#x9-480002&#34; id=&#34;QQ2-9-53&#34;&gt;Auto-Ballooning&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;   &lt;span class=&#34;chapterToc&#34; &gt;5 &lt;a
href=&#34;mainch5.html#x10-520005&#34; id=&#34;QQ2-10-58&#34;&gt;Experimental Evaluation&lt;/a&gt;&lt;/span&gt;


&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;5.1 &lt;a
href=&#34;mainch5.html#x10-530001&#34; id=&#34;QQ2-10-59&#34;&gt;Experimental Setup&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;5.2 &lt;a
href=&#34;mainch5.html#x10-540002&#34; id=&#34;QQ2-10-60&#34;&gt;Results&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;
&lt;span class=&#34;chapterToc&#34; &gt;6 &lt;a
href=&#34;mainch6.html#x11-600006&#34; id=&#34;QQ2-10-62&#34;&gt;Conclusions&lt;/a&gt;&lt;/span&gt;


&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;6.1 &lt;a
href=&#34;mainch6.html#x11-610001&#34; id=&#34;QQ2-10-63&#34;&gt;Summary&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;    &lt;span class=&#34;sectionToc&#34; &gt;6.2 &lt;a
href=&#34;mainch6.html#x11-620002&#34; id=&#34;QQ2-10-64&#34;&gt;Future Work&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;
&lt;span class=&#34;likechapterToc&#34; &gt;&lt;a
href=&#34;mainli5.html#x12-660003&#34; id=&#34;QQ2-2-61&#34;&gt;References&lt;/a&gt;&lt;/span&gt;
&lt;br /&gt;

&lt;/div&gt;




</description>
    </item>
    
    <item>
      <title>Experimental Evaluation</title>
      <link>http://www.ninjaducks.in/thesis/mainch5.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainch5.html</guid>
      <description>
&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch6.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainch4.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch4.html#tailmainch4.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;#tailmainch5.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch5.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;h2 class=&#34;chapterHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;Chapter 5&lt;/span&gt;&lt;br /&gt;&lt;a
href=&#34;main.html#QQ2-10-58&#34; id=&#34;x10-520005&#34;&gt;Experimental Evaluation&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We have built our DRS for the QEMU-KVM hypervisor. It uses the &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;libvirt&lt;/span&gt;&lt;/em&gt; APIs for
managing the virtual machines and &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Openstack&lt;/span&gt;&lt;/em&gt; [&lt;a id=&#34;page.69&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-openstack&#34; &gt;26&lt;/a&gt;] mainly for cloud management and
software deﬁned networking along with live-migration support. For the distributed
key-value store, we use &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;etcd&lt;/span&gt;&lt;/em&gt; [&lt;a
href=&#34;mainli5.html#X0-etcd&#34; &gt;27&lt;/a&gt;]. We have conducted several experiments to determine the
eﬀectiveness of our DRS. The experiments relating to monitoring and auto-ballooning
aspect of the DRS have been described below.
&lt;a
id=&#34;x10-52001r53&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;5.1   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-10-59&#34; id=&#34;x10-530001&#34;&gt;Experimental Setup&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Our experimental setup consists of six physical machines. Each physical machine has an 8
core Intel Core i7 3.5GHz CPU, 16 GB memory, 1Gbps NIC and runs the 64 bit Ubuntu
14.04 with Linux kernel version 3.19 . We have installed Openstack on these 6 nodes such
that one of the nodes is the controller node(runs the Openstack management services)
and the other ﬁve are the compute nodes (run the actual VMs). The nodes are
connected to a gigabit local network, which they use for transferring data while live
migration and for communicating with the outside network. The disks of all the
VMs reside on a shared NFS server, and hence, live migration needs to just
transfer the memory of the VM between the hosts, and not the disks. Each of the
compute nodes also run the DRS software created by us. The controller and
two separate nodes (separate from the controller and the compute nodes) run
etcd, with a cluster size of three, which provides a fault tolerance of degree one
[&lt;a
href=&#34;mainli5.html#X0-etcd-ad&#34; &gt;28&lt;/a&gt;]. All the VMs that we use run 64 bit Ubuntu 12.04 cloud image. The VMs
can be of two sizes - 1 vCPU with 2 GB RAM(small) or 2 vCPU with 4 GB
RAM(large).
&lt;/p&gt;
&lt;p&gt;   There are three types of workloads run by these VMs. One workload is memory
intensive, one is CPU intensive and one of the workloads is a mix of the two. The


memory intensive workload is a program written by us which consumes a total
of 1800MB. The program runs in two phases - the allocation phase and the
retention phase. The allocation phase starts when the program starts. In the
allocation phase, the program tries to allocate 100MB memory using &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;malloc&lt;/span&gt;&lt;/em&gt; and
then sleeps for two seconds. This step is performed iteratively till the allocated
memory has reached 1800MB. Notably, it may take more than 18 iterations for the
allocation to reach 1800MB because malloc will return &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;null&lt;/span&gt;&lt;/em&gt; if it cannot allocate
memory due to shortage of memory and the program will sleep for two more
seconds. So, the length of the allocation phase depends on the availability of
memory. After the allocation phase, retention phase starts, where the program
retains the allocated memory for 300 seconds, and does no more allocations.
After the retention phase, the program ends. We will refer to this workload as
&lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;usemem&lt;/span&gt;&lt;/em&gt;.
&lt;/p&gt;
&lt;p&gt;   For the other two types of workloads, we have chosen two SPEC CPU 2006 V1.2
benchmarks [&lt;a id=&#34;page.70&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-Henning:2006:SCB:1186736.1186737&#34; &gt;29&lt;/a&gt;]. For CPU intensive workload, we run the &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;libquantum&lt;/span&gt;&lt;/em&gt; benchmark. The
libquantum benchmark tries to solve certain computationally hard problems using the
simulation of a quantum computer. At runtime, the benchmark consumes 100% of a
vCPU and about 50MB memory. For the CPU and memory intensive workload, we
use the &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;mcf &lt;/span&gt;&lt;/em&gt; benchmark. The mcf benchmark solves the single-depot vehicle
scheduling problem in the planning process of public transportation companies
using the network simplex algorithm accelerated with a column generation. At
runtime, the mcf benchmark consumes 100% of a vCPU and about 1800MB
memory.
&lt;/p&gt;
&lt;p&gt;   Large VMs run two workloads in two separate threads simultaneously, while the
small VMs runs only one workload in a single thread. Each thread randomly
chooses a workload from the three workloads described above, runs it and
calculates the time it took to run the workload, sleeps for a randomly chosen
time between 0 and 90 seconds, and then repeats this process. Each compute
node has four large VMs and three small VMs. Keeping aside one core and


two GB memory for the hypervisor, this gives us an overcommitment ratio of
&lt;!--l. 12--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi&gt;1.57&lt;/mi&gt;&lt;/math&gt; for
both CPU and memory.
&lt;a
id=&#34;x10-53001r59&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;5.2   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-10-60&#34; id=&#34;x10-540002&#34;&gt;Results&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The experiment that we ran was to determine the eﬀectiveness of autoballooning in
memory overcommitment. For this, we monitored two hosts named compute2 and
compute3 respectively, running seven VMs as described in the previous section. We
disabled live-migration in the DRS on the both hosts. On compute3, autoballoning was
also disabled. We compare the results obtained after running the experiment for about 17
hours.
&lt;a
id=&#34;x10-54001r55&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;5.2.1   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-10-61&#34; id=&#34;x10-550001&#34;&gt;Analyzing Auto-Ballooning&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Figure &lt;a
href=&#34;#x10-55001r1&#34;&gt;5.1&lt;!--tex4ht:ref: fig:mem --&gt;&lt;/a&gt; shows the diﬀerent memory metrics of compute2 and compute3 hosts
plotted against time. From these graphs, the most remarkable diﬀerence that we
can see is in the swap memory on both the machines. On compute3, the swap
memory rose to very high levels of about 7GB, which is equal to the amount of
memory we have overcommited. On compute 2, the swap memory remained
very low throughout the experiment, remaining below 1GB most of the time
and never going above 1.5GB. On compute3, the total used memory remains
almost constant and equal to maximum memory, while it keeps on ﬂuctuating
on compute2. This is because memory, once allocated, cannot be reclaimed on
compute3.


&lt;/p&gt;
&lt;p&gt;   &lt;a
id=&#34;x10-55001r1&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&#34;float&#34; /&gt;&lt;div class=&#34;float&#34;
&gt;



&lt;img
src=&#34;/images/thesis/mem-compute3.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/mem-compute2.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x10-55002&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 5.1: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Graphs showing diﬀerent memory metrics of compute3 (autoballooning
disabled) and compute 2 (autoballooning enabled). X-axis represents the time at
which the value was recorded, Y-axis shows the value.&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-55001r5 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfloat&#34; /&gt;
&lt;p&gt;   Figure &lt;a
href=&#34;#x10-55003r2&#34;&gt;5.2&lt;!--tex4ht:ref: fig:cpu --&gt;&lt;/a&gt; shows the CPU usage of compute2 and compute3 plotted against
time. In the graph, a few hours after starting the experiment, the CPU usage of
compute3 is consistently low, while compute2 makes better use of the CPU. This is
because of high levels of swap on compute 3. The mcf and usemem workloads
spend more time in performing I/O and hence are not able to utilize the CPU
eﬃciently.


&lt;/p&gt;
&lt;p&gt;   &lt;a
id=&#34;x10-55003r2&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&#34;float&#34; /&gt;&lt;div class=&#34;float&#34;
&gt;



&lt;img
src=&#34;/images/thesis/cpu-compute3.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/cpu-compute2.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x10-55004&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 5.2: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Graphs showing cpu usage of compute3 (autoballooning disabled) and
compute2 (autoballooning enabled). X-axis represents the time at which the value
was recorded, Y-axis shows the value.&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-55003r5 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfloat&#34; /&gt;
&lt;p&gt;   Table &lt;a
href=&#34;#x10-55005r1&#34;&gt;5.1&lt;!--tex4ht:ref: tab:count --&gt;&lt;/a&gt; lists the number of time each workload ran on both the machines.
Libquantum and mcf are CPU intensive. On compute2, CPU intensive workloads ran 303
times compared to 287 times on compute3 in the same time interval. Mcf and usemem are
memory intensive. On compute2, memory intensive workloads ran 357 times compared to
289 times on compute 3 in the same time interval. It clearly shows that there was better
utilization of the CPU and memory resources on compute2 resulting in a better overall
throughput.
&lt;/p&gt;
&lt;div class=&#34;table&#34;&gt;


&lt;p&gt;   &lt;a
id=&#34;x10-55005r1&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&#34;float&#34; /&gt;&lt;div class=&#34;float&#34;
&gt;


&lt;a
id=&#34;x10-55006&#34;&gt;&lt;/a&gt;
&lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Table 5.1: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Number of times each workload ran during the experiment&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-55005r5 --&gt;
&lt;div class=&#34;center&#34;
&gt;
&lt;p&gt;
&lt;table id=&#34;TBL-11&#34; class=&#34;tabular&#34;
cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;  
&gt;&lt;colgroup id=&#34;TBL-11-1g&#34;&gt;&lt;col
id=&#34;TBL-11-1&#34; /&gt;&lt;col
id=&#34;TBL-11-2&#34; /&gt;&lt;col
id=&#34;TBL-11-3&#34; /&gt;&lt;/colgroup&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-1-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-1-1&#34;  
class=&#34;td11&#34;&gt;                   &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-2-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-2-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                  &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-3-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-3-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Workload                &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-3-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Count-compute3      &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-3-3&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Count-compute2      &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-4-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-4-1&#34;  
class=&#34;td11&#34;&gt;                   &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-5-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-5-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                  &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-6-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-6-1&#34;  
class=&#34;td11&#34;&gt;                   &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-7-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-7-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                  &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-8-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-8-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;libquantum              &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-8-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;153                        &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-8-3&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;198                        &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-9-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-9-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;mcf                        &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-9-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;134                        &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-9-3&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;105                        &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-10-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-10-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;usemem                   &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-10-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;155                        &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-10-3&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;252                        &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-11-11-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-11-11-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                  &lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;


&lt;/div&gt;&lt;hr class=&#34;endfloat&#34; /&gt;
&lt;/div&gt;


&lt;p&gt;   &lt;a
id=&#34;x10-55007r3&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&#34;float&#34; /&gt;&lt;div class=&#34;float&#34;
&gt;



&lt;img
src=&#34;/images/thesis/time-compute3.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/time-compute2.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x10-55008&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 5.3: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Graphs showing the time taken by diﬀerent workloads on the two hosts.
The values greater than two hours have been ﬁltered out from the compute3 graph
for the sake of visibility. X-axis represents the time at which the value was recorded,
Y-axis shows the value.&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-55007r5 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfloat&#34; /&gt;
&lt;div class=&#34;table&#34;&gt;


&lt;p&gt;   &lt;a
id=&#34;x10-55009r2&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&#34;float&#34; /&gt;&lt;div class=&#34;float&#34;
&gt;


&lt;a
id=&#34;x10-55010&#34;&gt;&lt;/a&gt;
&lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Table 5.2: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Mean time taken by each workload to run&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-55009r5 --&gt;
&lt;div class=&#34;center&#34;
&gt;
&lt;p&gt;
&lt;table id=&#34;TBL-15&#34; class=&#34;tabular&#34;
cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;  
&gt;&lt;colgroup id=&#34;TBL-15-1g&#34;&gt;&lt;col
id=&#34;TBL-15-1&#34; /&gt;&lt;col
id=&#34;TBL-15-2&#34; /&gt;&lt;col
id=&#34;TBL-15-3&#34; /&gt;&lt;/colgroup&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-1-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-1-1&#34;  
class=&#34;td11&#34;&gt;                   &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-2-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-2-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                  &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-3-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-3-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Workload                &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-3-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Mean-compute3       &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-3-3&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Mean-compute2       &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-4-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-4-1&#34;  
class=&#34;td11&#34;&gt;                   &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-5-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-5-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                  &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-6-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-6-1&#34;  
class=&#34;td11&#34;&gt;                   &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-7-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-7-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                  &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-8-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-8-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;libquantum              &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-8-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;14.5 min                 &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-8-3&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;23.7 min                 &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-9-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-9-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;mcf                        &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-9-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;39.6 min                 &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-9-3&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;20.3 min                 &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-10-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-10-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;usemem                   &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-10-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;12.8 min                 &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-10-3&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;7.9 min                  &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-15-11-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-15-11-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                  &lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;


&lt;/div&gt;&lt;hr class=&#34;endfloat&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;   The graphs in Figure &lt;a
href=&#34;#x10-55007r3&#34;&gt;5.3&lt;!--tex4ht:ref: fig:time --&gt;&lt;/a&gt; show the time it took for the workloads to run plotted
against the time at which the workload completed. In the graph for compute3, we can see
that the time to complete the memory intensive workloads - mcf and usemem can grow to
more than two hours while it always remains below 33 minutes on compute2.
On top of this, some of the very large values have been ﬁltered out from the
graph of compute3. There were three such values for the mcf benchmark, which
were greater than 9 hours. On the contrary, the libquantum workload performs
better on compute3. This is because libquantum does not require much memory
and the CPU on compute3 is relatively free because the other workloads do
not utilize it well. Table &lt;a
href=&#34;#x10-55009r2&#34;&gt;5.2&lt;!--tex4ht:ref: tab:mean --&gt;&lt;/a&gt; shows the mean time it took for the workloads
to run. As expected, the libquantum performs better on compute3 while the
other workloads perform better on compute2. But mean time is not a good
metric to compare the eﬀectiveness of autoballooning. Throughput is a better
metric.
&lt;a
id=&#34;x10-55011r61&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;5.2.2   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-10-62&#34; id=&#34;x10-560002&#34;&gt;Analyzing CPU Hotspot Detection&lt;/a&gt;&lt;/h4&gt;


&lt;p&gt;   &lt;a
id=&#34;x10-56001r4&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&#34;float&#34; /&gt;&lt;div class=&#34;float&#34;
&gt;



&lt;img
src=&#34;/images/thesis/cpu-migration.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x10-56002&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 5.4: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;CPU usage of compute2 during one hour of the experiment. Blue dots
show the points at which migration was triggered. X-axis represents the time at
which the value was recorded, Y-axis shows the value in %&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-56001r5 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfloat&#34; /&gt;
&lt;p&gt;The graph in Figure &lt;a
href=&#34;#x10-56001r4&#34;&gt;5.4&lt;!--tex4ht:ref: fig:cpu-mig --&gt;&lt;/a&gt; shows the CPU usage of compute2 for one hour during the
experiment. The blue dots represent the instances at which migration was triggered.
Migration was disabled for this experiment, so no machines was actually migrated out of
this host. In the graph, the CPU usage is 100% in two intervals. First interval is from
around time 3:47 to 4:06 (interval1) and the second interval is from around 4:21 to 4:38
(interval2). However, migration is triggered only during interval1. This implies that
there was a hotspot due to CPU utilization only during interval1 and not during
interval2.
&lt;/p&gt;
&lt;hr class=&#34;figure&#34; /&gt;&lt;div class=&#34;figure&#34;
&gt;


&lt;a
id=&#34;x10-56003r5&#34;&gt;&lt;/a&gt;



&lt;p&gt;&lt;img
src=&#34;/images/thesis/cpu-big1.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/cpu-big2.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/cpu-big3.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/cpu-big4.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x10-56004&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;/p&gt;
&lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 5.5: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;CPU usage of all the large VMs on compute2 during 1 hour of the
experiment. X-axis represents the time at which the value was recorded, Y-axis
shows the value in %&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-56003r5 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfigure&#34; /&gt;
&lt;hr class=&#34;figure&#34; /&gt;&lt;div class=&#34;figure&#34;
&gt;


&lt;a
id=&#34;x10-56005r6&#34;&gt;&lt;/a&gt;



&lt;p&gt;&lt;img
src=&#34;/images/thesis/cpu-small1.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/cpu-small2.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/cpu-small3.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x10-56006&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;/p&gt;
&lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 5.6: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;CPU usage of all the small VMs on compute2 during 1 hour of the
experiment. X-axis represents the time at which the value was recorded, Y-axis
shows the value in %&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-56005r5 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfigure&#34; /&gt;
&lt;p&gt;   The graphs in Figure &lt;a
href=&#34;#x10-56003r5&#34;&gt;5.5&lt;!--tex4ht:ref: fig:cpu-large --&gt;&lt;/a&gt; and &lt;a
href=&#34;#x10-56005r6&#34;&gt;5.6&lt;!--tex4ht:ref: fig:cpu-small --&gt;&lt;/a&gt; show the CPU usage and steal time of individual
virtual machines on compute2 during that one hour. For a large virtual machines, 100%
CPU usage implies that it is using two vCPUs completely and 50% CPU usage implies
that it is using only one of its two vCPUs. For a small virtual machines, 100% CPU
usage means that it is using its only vCPU completely. From the graphs, we
can see that during interval1, large virtual machines are trying to use 6 vCPUs
and the small virtual machines are trying to use 3 vCPUs, which is a total of 9
vCPUs. The host has only 8 physical CPUs and hence, it is overloaded. This
also reﬂected in the steal time of the individual VMs which is higher than 10%
during interval1. During interval2, a total of 8 vCPUs are being used, which
is equal to the number of the physical CPUs, and hence there is no overload.
The steal time of the VMs are also low and migration is not triggered. These
observations show that steal time is an appropriate metric for determining CPU
hotspots.
&lt;a
id=&#34;x10-56007r62&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;5.2.3   &lt;/span&gt; &lt;a
href=&#34;#x10-570003&#34; id=&#34;x10-570003&#34;&gt;Analyzing the CUSUM algorithm&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Figure &lt;a
href=&#34;#x10-57001r7&#34;&gt;5.7&lt;!--tex4ht:ref: fig:etcd --&gt;&lt;/a&gt; shows a graph of one hour time duration of the experiment. The red dots in
the graph mark the diﬀerent points at which etcd was updated with the value of used
memory for the host compute2. It is evident from the graph that the algorithm is
successful in ﬁltering sudden changes in the value of load memory and only updates etcd
when the load proﬁle has changed. In the one hour time duration, etcd was updated 13
times. Without the ﬁltering algorithm, etcd would have been updated once in every 10
seconds i.e. 360 time in an hour, which is about 28 times more than the ﬁltering
algorithm. Overall during the 17 hour run of the experiment, etcd was updated just 266
times.


&lt;/p&gt;
&lt;p&gt;   &lt;a
id=&#34;x10-57001r7&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&#34;float&#34; /&gt;&lt;div class=&#34;float&#34;
&gt;



&lt;img
src=&#34;/images/thesis/etcd-mem.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x10-57002&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 5.7: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Graphs showing the points at which etcd is updated. X-axis represents
the time at which the value was recorded, Y-axis shows the value.&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-57001r5 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfloat&#34; /&gt;
&lt;a
id=&#34;x10-57003r63&#34;&gt;&lt;/a&gt;
&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;5.2.4   &lt;/span&gt; &lt;a
href=&#34;#x10-580004&#34; id=&#34;x10-580004&#34;&gt;Memory and CPU Footprint of DRS&lt;/a&gt;&lt;/h4&gt;
&lt;hr class=&#34;figure&#34; /&gt;&lt;div class=&#34;figure&#34;
&gt;


&lt;a
id=&#34;x10-58001r8&#34;&gt;&lt;/a&gt;



&lt;p&gt;&lt;img
src=&#34;/images/thesis/mem-self.png&#34; alt=&#34;PIC&#34;  
/&gt; &lt;img
src=&#34;/images/thesis/cpu-self.png&#34; alt=&#34;PIC&#34;  
/&gt;
&lt;a
id=&#34;x10-58002&#34;&gt;&lt;/a&gt;
&lt;br /&gt; &lt;/p&gt;
&lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Figure 5.8: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Graphs showing the CPU and memory used by the DRS. The memory
usage is shown in MBs abd CPU usage in %&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x10-58001r5 --&gt;


&lt;/div&gt;&lt;hr class=&#34;endfigure&#34; /&gt;
&lt;p&gt;   Graphs in Figure &lt;a
href=&#34;#x10-58001r8&#34;&gt;5.8&lt;!--tex4ht:ref: fig:self --&gt;&lt;/a&gt; show the resource usage statistics of the DRS algorithm. As we
can see, the CPU usage is always less then 0.35% which is almost negligible. The memory
used by the DRS algorithm is 50MB with the entire virtual memory size of the software
being just 350MB.
&lt;a
id=&#34;Q1-10-65&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;likesectionHead&#34;&gt;&lt;a
href=&#34;#x10-590004&#34; id=&#34;x10-590004&#34;&gt;Summary&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In this chapter, we described our experimental setup and compared the resource
utilization without autoballooning with the case when autoballooning was enabled. We
looked at the eﬀectiveness of steal time in identifying CPU hotspots. We also saw the
performance of the CUSUM algorithm which is used to ﬁlter sudden changes
in the resource usage from aﬀecting decision making of the DRS algorithm.
We also looked at the resources consumed by our implementation of the DRS
algorithm.


&lt;/p&gt;
&lt;!--l. 1--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch6.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainch4.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch4.html#tailmainch4.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;mainch5.html&#34; &gt;front&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch5.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;   &lt;a
id=&#34;tailmainch5.html&#34;&gt;&lt;/a&gt;        &lt;/p&gt;



</description>
    </item>
    
    <item>
      <title>Implementation of Monitoring and Auto-Ballooning</title>
      <link>http://www.ninjaducks.in/thesis/mainch4.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainch4.html</guid>
      <description>
 &lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
 href=&#34;mainch5.html&#34; &gt;next&lt;/a&gt;] [&lt;a
 href=&#34;mainch3.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
 href=&#34;mainch3.html#tailmainch3.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
 href=&#34;#tailmainch4.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
 href=&#34;main.html#mainch4.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
 &lt;h2 class=&#34;chapterHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;Chapter 4&lt;/span&gt;&lt;br /&gt;&lt;a
 href=&#34;main.html#QQ2-9-44&#34; id=&#34;x9-390004&#34;&gt;Implementation of Monitoring and Auto-Ballooning&lt;/a&gt;&lt;/h2&gt;
 &lt;p&gt;For the purpose of this thesis, we describe the implementation and experimentally
 evaluate only the monitoring and autoballooning parts of the DRS. The following sections
 describe the implementation details of these two components.
 &lt;a
 id=&#34;x9-39001r38&#34;&gt;&lt;/a&gt;
 &lt;/p&gt;

 &lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;4.1   &lt;/span&gt; &lt;a
 href=&#34;main.html#QQ2-9-45&#34; id=&#34;x9-400001&#34;&gt;Monitoring&lt;/a&gt;&lt;/h3&gt;
 &lt;p&gt;As we discussed in Chapter &lt;a
 href=&#34;mainch3.html#x8-310003&#34;&gt;3&lt;!--tex4ht:ref: chap:design --&gt;&lt;/a&gt;, the monitoring component runs on each host and monitors
 the host and the guests running on that host to detect hotspots. The next few sections
 discuss which metrics are monitored, why they are monitored, and how they are
 monitored. Our implementation is done in the &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;Python programming language&lt;/span&gt;&lt;/em&gt;. The
 monitoring service runs periodically in every ﬁxed time interval which is conﬁgurable. The
 default interval is set to then seconds. We will refer to this time interval as the &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;monitor&lt;/span&gt;
 &lt;span
 class=&#34;cmti-12&#34;&gt;interval&lt;/span&gt;&lt;/em&gt; in the rest of this document.
 &lt;a
 id=&#34;x9-40001r41&#34;&gt;&lt;/a&gt;
 &lt;/p&gt;

 &lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;4.1.1   &lt;/span&gt; &lt;a
 href=&#34;mainli2.html#QQ2-9-46&#34; id=&#34;x9-410001&#34;&gt;Host Monitoring&lt;/a&gt;&lt;/h4&gt;
 &lt;p&gt;Monitoring the host is simple because the Linux kernel exposes much of the needed
 information stored in its internal data structure through procfs [&lt;a id=&#34;page.41&#34;&gt;&lt;/a&gt;&lt;a
 href=&#34;mainli5.html#X0-procfs&#34; &gt;22&lt;/a&gt;]. Procfs is a ﬁlesystem
 in the Linux kernel, and hence can be accessed using the standard ﬁlesystem syscalls or
 through higher level API&amp;#x2019;s that exist in almost all programming languages for this
 purpose. Since the DRS is running on the host, it has unhindered access to all the
 information in procfs.
 &lt;/p&gt;

 &lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
 href=&#34;#x9-420001&#34; id=&#34;x9-420001&#34;&gt;CPU Monitoring&lt;/a&gt;&lt;/h5&gt;
 &lt;p&gt;For monitoring the CPU usage, we use the information in the &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/stat&lt;/span&gt;&lt;/em&gt; ﬁle. The


 &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/stat&lt;/span&gt;&lt;/em&gt; ﬁle has the following ﬁelds capturing how much time CPU spent doing what
 task [&lt;a
 href=&#34;mainli5.html#X0-procfs&#34; &gt;22&lt;/a&gt;].
 &lt;/p&gt;

    &lt;ul class=&#34;itemize1&#34;&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;user:&lt;/span&gt;&lt;/strong&gt; time spent in executing normal processes in the user mode
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;nice:&lt;/span&gt;&lt;/strong&gt; time spent in executing processes with positive nice value in the user
    mode
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;system:&lt;/span&gt;&lt;/strong&gt; time spent in executing processes in kernel mode
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;idle:&lt;/span&gt;&lt;/strong&gt; time for which the cpu was idle
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;iowait:&lt;/span&gt;&lt;/strong&gt; time spent in waiting for I/O to complete
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;irq:&lt;/span&gt;&lt;/strong&gt; time spent in servicing interrupts
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;softirq:&lt;/span&gt;&lt;/strong&gt; time spent in servicing software interrupts
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;steal:&lt;/span&gt;&lt;/strong&gt; time spent waiting involuntarily. This metric is relevant when the kernel
    running under virtualization, and its vCPU thread has to wait in the ready
    queue because the host CPU is overloaded.
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;guest:&lt;/span&gt;&lt;/strong&gt; time spent running a normal guest (VM)
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;guest&lt;/span&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;_nice:&lt;/span&gt;&lt;/strong&gt; time spent running a guest (VM) with positive nice value.&lt;/li&gt;&lt;/ul&gt;


 &lt;p&gt;The time is measured in kernel jiﬃes. Jiﬀy is a counter that ticks on every timer interrupt.
 The interrupt frequency is 100Hz in majority of the systems. From the above
 values, we can get the total time that has passed, and time for which the cpu was
 busy.
 &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 29--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
 &lt;mtable
 class=&#34;multline-star&#34;&gt;
 &lt;mtr&gt;&lt;mtd
 class=&#34;multline-star&#34;&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;w&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;
 &lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;multline-star&#34;&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;q&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;w&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;q&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;q&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;_&lt;/mtext&gt;&lt;/mstyle&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;                      &lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;
 &lt;/math&gt;
 &lt;p&gt;
 &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 32--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
   &lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;q&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;q&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;_&lt;/mtext&gt;&lt;/mstyle&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;
 &lt;/math&gt;
 &lt;p&gt;
 &lt;/p&gt;
 &lt;p&gt;   The &lt;!--l. 34--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/math&gt;
 calculated here is the total time since the start of the system. Hence this will give the average


 cpu usage since the start of the system, which is not a useful metric for us. The average
 cpu usage in the previous monitor interval is more useful. To calculate that, we keep the
 &lt;!--l. 34--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/math&gt; and
 &lt;!--l. 34--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/math&gt; at the
 previous monitor interval and subtract those values from the current values.
 So,
 &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 35--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
       &lt;mi
 &gt;P&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;p&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mfrac&gt;&lt;mrow
 &gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;P&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/mrow&gt;
 &lt;mrow
 &gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;P&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;
 &lt;/math&gt;
 &lt;p&gt;
 &lt;/p&gt;

 &lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
 href=&#34;#x9-430001&#34; id=&#34;x9-430001&#34;&gt;Memory Monitoring&lt;/a&gt;&lt;/h5&gt;
 &lt;p&gt;Memory usage information is present in the &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/meminfo&lt;/span&gt;&lt;/em&gt; ﬁle [&lt;a id=&#34;page.44&#34;&gt;&lt;/a&gt;&lt;a
 href=&#34;mainli5.html#X0-procfs&#34; &gt;22&lt;/a&gt;]. For monitoring, we
 need several memory metrics which are described below. &lt;/p&gt;

    &lt;ul class=&#34;itemize1&#34;&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Total memory:&lt;/span&gt;&lt;/strong&gt; The total usable memory present on the host. Present in the
    ﬁrst line of the &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/meminfo&lt;/span&gt;&lt;/em&gt;.
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Used memory:&lt;/span&gt;&lt;/strong&gt; Total memory used by the host. This includes the memory
    used by the VMs, host&amp;#x2019;s own processes and the page caches. This can be
    calculated by subtracting free memory, which is present in the second line of
    &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/meminfo&lt;/span&gt;&lt;/em&gt; ﬁle, from total memory.
    &lt;/li&gt;


    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Available  memory:&lt;/span&gt;&lt;/strong&gt; This  provides  an  estimate  of  how  much  memory  is
    available to any new application that will be started on the system. This is
    diﬀerent from free memory because used memory also contains page caches,
    which can be reclaimed in case no free memory is left and an application
    requires more memory. Some of the slab memory used by the kernel is also
    reclaimable. The estimate also accounts for the fact that the system needs
    some page cache to function well, and that not all reclaimable slab can be
    reclaimed. It is present in the third line of &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/meminfo&lt;/span&gt;&lt;/em&gt; ﬁle.
    &lt;p&gt;Available memory is an important metric for us, because it basically tells us
    how much memory is available for the new VMs. It is better than free memory,
    because free memory does not take into account page caches which can be
    reclaimed.
    &lt;/p&gt;
 &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Hypervisor Load:&lt;/span&gt;&lt;/strong&gt; This is an important metric because we want to have a
    lower bound on how much memory is available for the hypervisor to function.
    We  call  this  memory  &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;hypervisor  reserved  memory&lt;/span&gt;&lt;/em&gt;.  While  calculating  the
    amount of memory that is free for VMs to use, we do not want to use the
    memory that is reserved for the hypervisor.
    &lt;p&gt;For calculating the hypervisor load, we ﬁrst calculate the VM load i.e. the
    amount of memory used by the virtual machines on the system. The VM load is
    calculated by looking at the RSS (resident set size) of all the virtual machines
    running on the host. Since QEMU-KVM treats each VM as a separate process,
    we  need  to  get  the  RSS  of  all  the  processes  which  are  running  a  virtual
    machine. The &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/[pid]/statm&lt;/span&gt;&lt;/em&gt; ﬁle has this information for each process. After
    calculating the VMlLoad, the hypervisor load is calculated as


    &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 50--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
 &lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;p&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;p&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;R&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;,&lt;/mo&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt;&lt;mi
 &gt;P&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;h&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt;&lt;mi
 &gt;V&lt;/mi&gt; &lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;
 &lt;/math&gt;
    &lt;p&gt;
    &lt;/p&gt;
 &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Load Memory: &lt;/span&gt;&lt;/strong&gt; This metric represents the total memory that is loaded and
    hence, not available for use by any new VM or for existing VMs. It is calculated
    as
    &lt;!--tex4ht:inline--&gt;&lt;!--l. 53--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
      &lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;p&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;E&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;p&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;R&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;p&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;,&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;
 &lt;/math&gt;
    &lt;p&gt;
    &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 55--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
 &lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt;&lt;mi
 &gt;A&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;b&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;p&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;E&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;
 &lt;/math&gt;
    &lt;p&gt;


    &lt;/p&gt;
 &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Idle Memory: &lt;/span&gt;&lt;/strong&gt; Idle Memory is the memory which has been consumed by the
    VMs but is sitting idle inside the VM and can be ballooned out. Thus, it can
    be used by the existing VMs or any new VM that is migrated to the host. Its
    calculation is described later in the Section &lt;a
 href=&#34;#x9-440002&#34;&gt;4.1.2&lt;!--tex4ht:ref: sec:guestmon --&gt;&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;
 &lt;a
 id=&#34;x9-43001r46&#34;&gt;&lt;/a&gt;
 &lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;4.1.2   &lt;/span&gt; &lt;a
 href=&#34;mainli2.html#QQ2-9-49&#34; id=&#34;x9-440002&#34;&gt;Guest Monitoring&lt;/a&gt;&lt;/h4&gt;
 &lt;p&gt;Monitoring a VM is more complex than monitoring the host because some of the metrics
 needed are not exposed by the VM to the host in any conventional way. Host operating
 system just gets to see the process abstraction of each virtual machine. So, the host has
 only as much information about each guest as it has about the rest of the processes
 running on it. In the next two sections, along with which metrics have been monitored, we
 have discuss some new techniques which we use to get some of the information from the
 guest VMs.
 &lt;/p&gt;

 &lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
 href=&#34;#x9-450002&#34; id=&#34;x9-450002&#34;&gt;CPU Monitoring&lt;/a&gt;&lt;/h5&gt;
 &lt;p&gt;CPU monitoring for a guest VM is straightforward because the host OS has the
 scheduling information for each process it is running. This information is exposed by the
 procfs. The metrics related to CPU utilization measured are discussed below.
 &lt;/p&gt;

    &lt;ul class=&#34;itemize1&#34;&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Busy  Time:&lt;/span&gt;&lt;/strong&gt;  This  is  the  time  for  which  any  of  the  vCPUs  of  the
    VM  was  scheduled  onto  any  of  the  physical  CPUs  of  the  host.  The
    scheduling  information  for  each  thread  of  a  process  is  present  inside  the
    &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/[pid]/task/[tid]/schedstat&lt;/span&gt;&lt;/em&gt; ﬁle [&lt;a id=&#34;page.47&#34;&gt;&lt;/a&gt;&lt;a
 href=&#34;mainli5.html#X0-procfs&#34; &gt;22&lt;/a&gt;]. We can get the busy time for each
    thread in nanoseconds from here. Adding the busy time for all the vCPU
    threads gives us the total busy time. The total time elasped has already been
    calculated in Section &lt;a
 href=&#34;#x9-420001&#34;&gt;4.1.1&lt;!--tex4ht:ref: sec:cpumon --&gt;&lt;/a&gt;. We do calculation similar to Section &lt;a
 href=&#34;#x9-420001&#34;&gt;4.1.1&lt;!--tex4ht:ref: sec:cpumon --&gt;&lt;/a&gt; to get


    the busy time percentage in previous monitor interval for all the guests.
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Steal Time:&lt;/span&gt;&lt;/strong&gt; Steal time [&lt;a id=&#34;page.48&#34;&gt;&lt;/a&gt;&lt;a
 href=&#34;mainli5.html#X0-ehrhardt2013cpu&#34; &gt;23&lt;/a&gt;] is the time for which a vCPU thread waits in the
    ready queue while the CPU is busy executing some other process. Steal time
    has direct correlation to the amount of load on CPU and is useful in predicting
    whether the CPU is overloaded. Steal times for each thread is present inside
    the &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/[pid]/task/[tid]/schedstat&lt;/span&gt;&lt;/em&gt; [&lt;a
 href=&#34;mainli5.html#X0-procfs&#34; &gt;22&lt;/a&gt;]. For each VM, we add the steal times
    of all its vCPU threads and calculate the average steal time percentage in the
    previous monitor interval.
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Estimated CPU Demand:&lt;/span&gt;&lt;/strong&gt; Estimated CPU demand is useful for predicting
    the amount of CPU a VM can consume if the host is not overloaded i.e. the
    steal time is 0. This value will be helpful during migration to check whether the
    CPU demands of the VM can be satisﬁed by the destination. It is calculated
    by adding a scaled value of steal percentage to the current busy percentage.
    &lt;!--tex4ht:inline--&gt;&lt;!--l. 69--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
     &lt;mi
 &gt;E&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;P&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;D&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;P&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mfrac&gt;&lt;mrow
 &gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/mrow&gt;
 &lt;mrow
 &gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mfrac&gt;&lt;mrow
 &gt;&lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/mrow&gt;
 &lt;mrow
 &gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;
 &lt;/math&gt;
    &lt;p&gt;&lt;/p&gt;
 &lt;/li&gt;&lt;/ul&gt;
 &lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
 href=&#34;#x9-460002&#34; id=&#34;x9-460002&#34;&gt;Memory Monitoring&lt;/a&gt;&lt;/h5&gt;
 &lt;p&gt;Getting the memory usage statistics is diﬃcult because the host has no information about
 the memory management of the guest. The host only knows the amount of memory
 allocated by each guest. For calculating the idle memory of each guest, we need the


 amount of &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;available memory&lt;/span&gt;&lt;/em&gt; inside the VM.
 &lt;/p&gt;
 &lt;p&gt;   One way for a guest VM to expose some information to the host is through a device
 driver. In a virtualized environment, all the devices available to a VM are virtual devices
 which are emulated by the hypervisor. So, a device driver running inside the VM can send
 some information to the device which is emulated by the hypervisor. The virtio balloon
 driver in the Linux kernel has a way of exposing the memory statistics to the host. It
 gives the total memory, free memory, swap in, major page faults, minor page fault
 metrics. We have modiﬁed the balloon driver to expose the available memory metric to
 the host too. We have also modiﬁed the backend virtio balloon hardware in
 QEMU to take the Available Memory metric from the balloon driver inside
 the guest. The following metrics related to the memory usage of the VMs are
 monitored. Figure &lt;a
 href=&#34;#x9-46001r1&#34;&gt;4.1&lt;!--tex4ht:ref: fig:mem1 --&gt;&lt;/a&gt; shows the relative sizes of diﬀerent memory metrics calculated.
 &lt;/p&gt;
 &lt;hr class=&#34;figure&#34; /&gt;&lt;div class=&#34;figure&#34;
 &gt;


 &lt;a
 id=&#34;x9-46001r1&#34;&gt;&lt;/a&gt;



 &lt;p&gt;&lt;img
 src=&#34;http://www.ninjaducks.in/images/thesis/mem1.png&#34; alt=&#34;PIC&#34;  
 /&gt;
 &lt;a
 id=&#34;x9-46002&#34;&gt;&lt;/a&gt;
 &lt;br /&gt; &lt;/p&gt;
 &lt;div class=&#34;caption&#34;
 &gt;&lt;span class=&#34;id&#34;&gt;Figure 4.1: &lt;/span&gt;&lt;span  
 class=&#34;content&#34;&gt;Relative sizes of diﬀerent types of memory metrics&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x9-46001r4 --&gt;


 &lt;/div&gt;&lt;hr class=&#34;endfigure&#34; /&gt;
    &lt;ul class=&#34;itemize1&#34;&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Maximum Memory:&lt;/span&gt;&lt;/strong&gt; This is the maximum memory that the guest can have.
    The guest cannot be ballooned up after this point. We obtain this metric by
    using the API QEMU provides for this purpose.
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Current Memory:&lt;/span&gt;&lt;/strong&gt; This the amount of memory the guest has after taking
    the ballooned memory into account. From the point of view of the guest, this
    is its total memory, which can be increased or decreased by ballooning. The
    maximum limit for the current memory is the maximum memory. The &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;total&lt;/span&gt;
    &lt;span
 class=&#34;cmti-12&#34;&gt;memory&lt;/span&gt;&lt;/em&gt; statistic obtained through the virtio balloon driver represents this
    metric.
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Used Memory:&lt;/span&gt;&lt;/strong&gt; This is the memory which is being used by the guest. It
    includes all the page caches along with the memory being used by the processes
    inside the guest.
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Available Memory:&lt;/span&gt;&lt;/strong&gt; This is the amount of available memory inside the guest.
    The concept of available memory has been discussed in Section &lt;a
 href=&#34;#x9-430001&#34;&gt;4.1.1&lt;!--tex4ht:ref: impl:hostmemmon --&gt;&lt;/a&gt;. We have
    modiﬁed the virtio balloon driver to obtain this metric.
    &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Allocated Memory:&lt;/span&gt;&lt;/strong&gt; This is the amount of memory of the guest that is
    backed by physical memory on the host. Allocated memory is diﬀerent from
    current memory because the memory is allocated to the vritual machines on
    demand. This also may not equal to the used memory of the guest. Without
    ballooning, the memory, once allocated to a guest, is not reclaimed from it.
    So, the usage of a guest may keep on changing, but the allocated memory


    will always be equal to the maximum used memory in the guest&amp;#x2019;s lifetime.
    Allocated memory is helpful in calculating the idle memory.
    &lt;p&gt;The allocated memory is calculated by looking at the virtual memory maps
    of the QEMU-KVM process corresponding to each VM. This information is
    present inside the &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;/proc/[pid]/smaps&lt;/span&gt;&lt;/em&gt; ﬁle [&lt;a id=&#34;page.53&#34;&gt;&lt;/a&gt;&lt;a
 href=&#34;mainli5.html#X0-procfs&#34; &gt;22&lt;/a&gt;] for each process. The RAM of
    the guest VM is allocated by the QEMU process by doing a malloc of the size
    of maximum memory. Thus, it is one big contiguous chunk of memory in the
    heap memory of the process. From the information about diﬀerent memory
    sections of the process present in this ﬁle, we look for the heap memory chunk
    of the size of VM&amp;#x2019;s maximum memory. The RSS (resident set size) of this
    chunk of memory gives us the amount of memory in the VM that is backed
    by physical storage.
    &lt;/p&gt;
 &lt;p&gt;In this chunk of allocated memory, there is some amount of memory that
    QEMU uses to store some metadata about the pages of the guest VM. Hence,
    this entire memory is not available to the guest. This part of memory cannot
    be reclaimed by ballooning. This overhead is constant and depends on the
    maximum memory size of the guest. We call this overhead as QEMU overhead.
    QEMU overhead needs to be deducted from the RSS. We use a piecewise
    continuous function to model the QEMU overhead. The values for the QEMU
    overhead in diﬀerent scenarios were determined experimentally.
 &lt;/p&gt;
 &lt;div class=&#34;math-display&#34;&gt;&lt;!--l. 92--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;&lt;mrow
 &gt;
 &lt;mi
 &gt;Q&lt;/mi&gt;&lt;mi
 &gt;E&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;O&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;h&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt;  &lt;mfenced separators=&#34;&#34;
 open=&#34;{&#34;  close=&#34;&#34; &gt;&lt;mrow&gt; &lt;mtable  align=&#34;axis&#34; style=&#34;&#34;  
 equalrows=&#34;false&#34; columnlines=&#34;none&#34; equalcolumns=&#34;false&#34; class=&#34;array&#34;&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;if &lt;/mtext&gt;&lt;mstyle
 class=&#34;math&#34;&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003C;&lt;/mo&gt;&lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mn&gt;4&lt;/mn&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;/mstyle&gt;&lt;mtext  &gt;&lt;/mtext&gt;&lt;/mstyle&gt;           &lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt; &lt;mn&gt;3&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt; &lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;if &lt;/mtext&gt;&lt;mstyle
 class=&#34;math&#34;&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003C;&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003C;&lt;/mo&gt;&lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;/mstyle&gt;&lt;mtext  &gt;&lt;/mtext&gt;&lt;/mstyle&gt;&lt;/mtd&gt;
 &lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt; &lt;mn&gt;4&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;if &lt;/mtext&gt;&lt;mstyle
 class=&#34;math&#34;&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003C;&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003C;&lt;/mo&gt;&lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;/mstyle&gt;&lt;mtext  &gt;&lt;/mtext&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt; &lt;mn&gt;5&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt; &lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;if &lt;/mtext&gt;&lt;mstyle
 class=&#34;math&#34;&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003E;&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;/mstyle&gt;&lt;mtext  &gt;&lt;/mtext&gt;&lt;/mstyle&gt;&lt;/mtd&gt;
 &lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;         &lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;!--@{}l@{\quad }l@{}--&gt;&lt;/mtable&gt;                                                                                   &lt;/mrow&gt;&lt;/mfenced&gt;
 &lt;/mrow&gt;&lt;/math&gt;&lt;/div&gt;


    &lt;p&gt;
    &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 101--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
                  &lt;mi
 &gt;A&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;R&lt;/mi&gt;&lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;S&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;Q&lt;/mi&gt;&lt;mi
 &gt;E&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;O&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;h&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;
 &lt;/math&gt;
    &lt;p&gt;
    &lt;/p&gt;
 &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Load Memory:&lt;/span&gt;&lt;/strong&gt; This is the amount of memory that is loaded i.e. is being
    used by the processes of the guest and hence the current memory should not
    go below this point.
    &lt;!--tex4ht:inline--&gt;&lt;!--l. 103--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
                &lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;A&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;b&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;
 &lt;/math&gt;
    &lt;p&gt;
    &lt;/p&gt;
 &lt;/li&gt;
    &lt;li class=&#34;itemize&#34;&gt;&lt;strong&gt;&lt;span
 class=&#34;cmbx-12&#34;&gt;Idle Memory:&lt;/span&gt;&lt;/strong&gt; Idle memory is the amount of memory that is allocated, but
    is not being used by the guest, and hence, can be reclaimed. A lower bound on
    the current memory of the guest has been kept to avoid ballooning so much
    memory out of it that it is unable to function. This bound is called &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;guest&lt;/span&gt;


    &lt;span
 class=&#34;cmti-12&#34;&gt;reserved&lt;/span&gt;&lt;/em&gt;. So,
    &lt;!--tex4ht:inline--&gt;&lt;!--l. 105--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
                  &lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;w&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;,&lt;/mo&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;R&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;
 &lt;/math&gt;
    &lt;p&gt;
    &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 106--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
              &lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;A&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;w&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;,&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;
 &lt;/math&gt;
    &lt;p&gt; Based on how the idle memory is reclaimed, it can be divided into two types
    - hard idle memory and soft idle memory. Their importance and the diﬀerence
    between them have been explained in Section &lt;a
 href=&#34;#x9-490001&#34;&gt;4.2.1&lt;!--tex4ht:ref: sec:bal --&gt;&lt;/a&gt;.&lt;/p&gt;
 &lt;/li&gt;&lt;/ul&gt;
 &lt;a
 id=&#34;x9-46003r49&#34;&gt;&lt;/a&gt;
 &lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;4.1.3   &lt;/span&gt; &lt;a
 href=&#34;mainli2.html#QQ2-9-52&#34; id=&#34;x9-470003&#34;&gt;Hotspot Detection and Key-Value Store Updation&lt;/a&gt;&lt;/h4&gt;
 &lt;p&gt;The hotspot detection algorithm should be robust enough not to generate false alarms. A
 simple threshold based algorithm which takes absolute or average values into account can
 raise many false alarms. Andreolini et al. [&lt;a id=&#34;page.55&#34;&gt;&lt;/a&gt;&lt;a
 href=&#34;mainli5.html#X0-andreolini2009dynamic&#34; &gt;24&lt;/a&gt;] have shown the drawbacks of such
 algorithms and proposed a more robust statistical model to detect changes in the


 load proﬁle of a machine which is based on the CUSUM (Cumulative Sum)
 algorithm [&lt;a
 href=&#34;mainli5.html#X0-page1957estimating&#34; &gt;25&lt;/a&gt;]. We have used this algorithm for detecting hotspots and the time to
 update the key-value store. The algorithm is described below for the sake of
 completeness.
 &lt;/p&gt;
 &lt;p&gt;   The hotspots due to memory overload are detected using the load memory
 metric of the host. The values for load memory are recorded in ever monitor
 interval to form a time series. Exponential average of the data is calculated
 as
 &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 114--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
                       &lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;μ&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;α&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;μ&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub
 &gt;
 &lt;/math&gt;
 &lt;p&gt; The value of &lt;!--l. 115--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;α&lt;/mi&gt;&lt;/math&gt; has been
 chosen to be &lt;!--l. 115--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;.&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;. The algorithm
 detects abrupt increase in &lt;!--l. 115--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;μ&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt;&lt;/math&gt;
 using &lt;!--l. 115--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt;&lt;/math&gt;.
 &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 116--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
                  &lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;;&lt;/mo&gt; &lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;μ&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
 &gt;K&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;
 &lt;/math&gt;
 &lt;p&gt; &lt;!--l. 117--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt;&lt;/math&gt; measures all the


 deviations from &lt;!--l. 117--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;μ&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt;&lt;/math&gt; that
 are greater than &lt;!--l. 117--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;K&lt;/mi&gt;&lt;/math&gt;.
 &lt;!--l. 117--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;K&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mfrac&gt;&lt;mrow
 &gt;&lt;mi
 &gt;Δ&lt;/mi&gt;&lt;/mrow&gt;
 &lt;mrow
 &gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt; &lt;/math&gt; where
 &lt;!--l. 117--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;Δ&lt;/mi&gt;&lt;/math&gt;
 is the minimum shift to be detected. It has been set to
 (&lt;!--l. 118--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;.&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;5&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/math&gt;) to detect minimum 1%
 change in the value of &lt;!--l. 118--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;/math&gt;.
 Change in the load proﬁle of the host is triggered when
 &lt;!--l. 118--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003E;&lt;/mo&gt; &lt;mi
 &gt;H&lt;/mi&gt;&lt;/math&gt; where
 &lt;!--l. 118--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;H&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;h&lt;/mi&gt;&lt;mi
 &gt;σ&lt;/mi&gt;&lt;/math&gt;,
 &lt;!--l. 118--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;h&lt;/mi&gt;&lt;/math&gt; being a design
 parameter and &lt;!--l. 118--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;σ&lt;/mi&gt;&lt;/math&gt;
 being the standard deviation of the time series upto that point. We have set
 &lt;!--l. 118--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;h&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mn&gt;7&lt;/mn&gt;&lt;/math&gt;,
 which means that the load proﬁle change is detected in an average of 14 samples
 [&lt;a id=&#34;page.56&#34;&gt;&lt;/a&gt;&lt;a
 href=&#34;mainli5.html#X0-andreolini2009dynamic&#34; &gt;24&lt;/a&gt;]. When the load-proﬁle changes, the key-value store is updated with
 &lt;!--l. 119--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;/math&gt;. When the load
 proﬁle changes and &lt;!--l. 119--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mrow
 &gt;&lt;mi
 &gt;μ&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
 &gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
 &gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003E;&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;.&lt;/mo&gt;&lt;mn&gt;8&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;,
 hotspot is triggered and the migration service becomes active.
 &lt;/p&gt;
 &lt;p&gt;   The hotspots in the CPU usage are also calculated in a similar way. The
 only diﬀerence is that the CUSUM algorithm runs on the steal time of all the
 guests, and any guest can trigger hotspot when its load proﬁle changes and its
 &lt;!--l. 121--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;A&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003E;&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;%&lt;/mi&gt;&lt;/math&gt;.
 Additionally, the CUSUM algorithm runs on the busy time of the host to trigger
 the updation of the key-value store. The value stored in the key-value store is
 &lt;!--l. 121--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;N&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;b&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;O&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;P&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;P&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;
 &lt;a
 id=&#34;x9-47001r45&#34;&gt;&lt;/a&gt;
 &lt;/p&gt;



 &lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;4.2   &lt;/span&gt; &lt;a
 href=&#34;main.html#QQ2-9-53&#34; id=&#34;x9-480002&#34;&gt;Auto-Ballooning&lt;/a&gt;&lt;/h3&gt;
 &lt;p&gt;Ballooning is a technique for increasing or decreasing the current memory of a guest.
 Auto-Ballooning is the process of automatically balancing memory amongst multiple
 guests running on a system by taking some memory from the idle guests and giving it to
 the needy guests. Auto-Ballooning is the most essential component for memory
 overcommitment.
 &lt;a
 id=&#34;x9-48001r52&#34;&gt;&lt;/a&gt;
 &lt;/p&gt;

 &lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;4.2.1   &lt;/span&gt; &lt;a
 href=&#34;mainli2.html#QQ2-9-54&#34; id=&#34;x9-490001&#34;&gt;Hard Ballooning and Soft Ballooning&lt;/a&gt;&lt;/h4&gt;
 &lt;p&gt;Depending upon the type of memory reclaimed ballooning can be classiﬁed into two types
 - hard ballooning and soft ballooning. Soft ballooning is the process of reclaiming memory
 which is free inside the guest while hard ballooning is the process of reclaiming memory
 which is used inside the guest.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
 &lt;!--tex4ht:inline--&gt;&lt;!--l. 134--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;&lt;mtable
 columnalign=&#34;left&#34; class=&#34;align-star&#34;&gt;
     &lt;mtr&gt;&lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-odd&#34;&gt;&lt;/mtd&gt;       &lt;mtd
 class=&#34;align-even&#34;&gt;&lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;w&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;,&lt;/mo&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;R&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;                 &lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-label&#34;&gt;&lt;/mtd&gt;       &lt;mtd
 class=&#34;align-label&#34;&gt;
     &lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-odd&#34;&gt;&lt;/mtd&gt;       &lt;mtd
 class=&#34;align-even&#34;&gt;&lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;A&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;c&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;w&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;,&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;       &lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-label&#34;&gt;&lt;/mtd&gt;       &lt;mtd
 class=&#34;align-label&#34;&gt;
     &lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-odd&#34;&gt;&lt;/mtd&gt;       &lt;mtd
 class=&#34;align-even&#34;&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;w&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;,&lt;/mo&gt;&lt;mi
 &gt;G&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;R&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;                 &lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-label&#34;&gt;&lt;/mtd&gt;       &lt;mtd
 class=&#34;align-label&#34;&gt;
     &lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-odd&#34;&gt;&lt;/mtd&gt;       &lt;mtd
 class=&#34;align-even&#34;&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;w&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;B&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;,&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;          &lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-label&#34;&gt;&lt;/mtd&gt;       &lt;mtd
 class=&#34;align-label&#34;&gt;
 &lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/math&gt;


 &lt;p&gt;   For soft ballooning, the guest is ballooned down to
 &lt;!--l. 136--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;, which
 will reclaim the SoftIdleMemory. To reclaim HardIdleMemory, the guest has to be ballooned
 down to &lt;!--l. 136--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;.
 Thus, ballooning down a guest from current memory to
 &lt;!--l. 136--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;
 will reclaim SoftIdleMemory. After this, ballooning down from
 &lt;!--l. 136--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;S&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;f&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt; to
 &lt;!--l. 136--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/math&gt;
 will reclaim no memory. Then, ballooning down from used memory to
 &lt;!--l. 136--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;
 will reclaim the HardIdleMemory. Figure &lt;a
 href=&#34;#x9-49001r2&#34;&gt;4.2&lt;!--tex4ht:ref: fig:mem2 --&gt;&lt;/a&gt; shows the two diﬀerent types of
 ballooning.
 &lt;/p&gt;
 &lt;hr class=&#34;figure&#34; /&gt;&lt;div class=&#34;figure&#34;
 &gt;


 &lt;a
 id=&#34;x9-49001r2&#34;&gt;&lt;/a&gt;



 &lt;p&gt;&lt;img
 src=&#34;http://www.ninjaducks.in/images/thesis/mem2.png&#34; alt=&#34;PIC&#34;  
 /&gt;
 &lt;a
 id=&#34;x9-49002&#34;&gt;&lt;/a&gt;
 &lt;br /&gt; &lt;/p&gt;
 &lt;div class=&#34;caption&#34;
 &gt;&lt;span class=&#34;id&#34;&gt;Figure 4.2: &lt;/span&gt;&lt;span  
 class=&#34;content&#34;&gt;Soft and hard ballooning&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x9-49001r4 --&gt;


 &lt;/div&gt;&lt;hr class=&#34;endfigure&#34; /&gt;
 &lt;a
 id=&#34;x9-49003r54&#34;&gt;&lt;/a&gt;
 &lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;4.2.2   &lt;/span&gt; &lt;a
 href=&#34;mainli2.html#QQ2-9-55&#34; id=&#34;x9-500002&#34;&gt;Auto-Ballooning Algorithm&lt;/a&gt;&lt;/h4&gt;
 &lt;p&gt;The autoballooning algorithm ﬁrst identiﬁes the guests with idle memory and the guests
 which need more memory. We have already described the method of calculating
 the idle memory earlier. We identify needy guests as the ones whose average
 load memory is greater than a certain threshold. We have kept the threshold to
 &lt;!--l. 146--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mn&gt;9&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;%&lt;/mi&gt;&lt;/math&gt; of
 the current memory of the guest. Needy guests are ballooned up in intervals of
 &lt;!--l. 146--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mi
 &gt;%&lt;/mi&gt;&lt;/math&gt; of
 their current memory. Total needed memory is the sum total of the memory needed
 by all the needy guests(which is 10% of the current memory for each needy
 guest).
 &lt;/p&gt;
 &lt;div class=&#34;math-display&#34;&gt;&lt;!--l. 147--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;&lt;mrow
 &gt;
 &lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;N&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;g&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt;  &lt;mfenced separators=&#34;&#34;
 open=&#34;{&#34;  close=&#34;&#34; &gt;&lt;mrow&gt; &lt;mtable  align=&#34;axis&#34; style=&#34;&#34;  
 equalrows=&#34;false&#34; columnlines=&#34;none&#34; equalcolumns=&#34;false&#34; class=&#34;array&#34;&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;&lt;/mtext&gt;&lt;mstyle
 class=&#34;math&#34;&gt;&lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;≥&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;.&lt;/mo&gt;&lt;mn&gt;9&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mstyle&gt;&lt;mtext  &gt;&lt;/mtext&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mi
 &gt;F&lt;/mi&gt; &lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt; &lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;otherwise&lt;/mtext&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt; &lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt; &lt;/mtd&gt;&lt;/mtr&gt; &lt;!--@{}l@{\quad }l@{}--&gt;&lt;/mtable&gt;                                                 &lt;/mrow&gt;&lt;/mfenced&gt;
 &lt;/mrow&gt;&lt;/math&gt;&lt;/div&gt;
 &lt;p&gt;


 &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 154--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
                  &lt;mi
 &gt;N&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;.&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mi
 &gt;C&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;
 &lt;/math&gt;
 &lt;p&gt;
 &lt;/p&gt;
 &lt;p&gt;   The &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;host unused memory&lt;/span&gt;&lt;/em&gt; is the amount of memory on the host which is neither used
 by/allocated to any guest nor is being used by the host, and hence, can be given
 away to any host by ballooning it up. Ballooning up a guest reduces the host
 unused memory, while ballooning a guest down decreases it. It is calculated as
 follows.
 &lt;/p&gt;
 &lt;!--tex4ht:inline--&gt;&lt;!--l. 161--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;&lt;mtable
 columnalign=&#34;left&#34; class=&#34;align-star&#34;&gt;
 &lt;mtr&gt;&lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-odd&#34;&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;A&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;b&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mi
 &gt;p&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;v&lt;/mi&gt;&lt;mi
 &gt;i&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;E&lt;/mi&gt;&lt;mi
 &gt;x&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;/mtd&gt;&lt;mtd
 class=&#34;align-even&#34;&gt;&lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;                                     &lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-label&#34;&gt;
 &lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-odd&#34;&gt;&lt;/mtd&gt;                                                               &lt;mtd
 class=&#34;align-even&#34;&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;                                   &lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-label&#34;&gt;&lt;/mtd&gt;&lt;mtd
 class=&#34;align-label&#34;&gt;
 &lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-odd&#34;&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mtd&gt;                        &lt;mtd
 class=&#34;align-even&#34;&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;L&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;I&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;&lt;mtd
 columnalign=&#34;right&#34; class=&#34;align-label&#34;&gt;&lt;/mtd&gt;&lt;mtd
 class=&#34;align-label&#34;&gt;
 &lt;mspace width=&#34;2em&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/math&gt;
 &lt;p&gt;Auto-Ballooning can be triggered in two cases -
 &lt;!--l. 162--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003C;&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;.&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt; or
 &lt;!--l. 162--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;N&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003E;&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;. The ﬁrst
 case is important to keep the amount of swapped memory on the host low. To handle the ﬁrst
 case, ﬁrst the soft idle memory and then the hard idle memory form the guests is ballooned out
 till the &lt;!--l. 162--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
 class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
 &gt;H&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;U&lt;/mi&gt;&lt;mi
 &gt;n&lt;/mi&gt;&lt;mi
 &gt;u&lt;/mi&gt;&lt;mi
 &gt;s&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;d&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt; &lt;mo
 class=&#34;MathClass-rel&#34;&gt;&amp;#x003C;&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt;&lt;mo
 class=&#34;MathClass-punc&#34;&gt;.&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt; &lt;mo
 class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mi
 &gt;T&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;t&lt;/mi&gt;&lt;mi
 &gt;a&lt;/mi&gt;&lt;mi
 &gt;l&lt;/mi&gt;&lt;mi
 &gt;M&lt;/mi&gt;&lt;mi
 &gt;e&lt;/mi&gt;&lt;mi
 &gt;m&lt;/mi&gt;&lt;mi
 &gt;o&lt;/mi&gt;&lt;mi
 &gt;r&lt;/mi&gt;&lt;mi
 &gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
 class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;. If


 the idle memory is exhausted before this 20% memory becomes unused, swapping is
 inevitable and the job of resolving it is left to the migration service.
 &lt;/p&gt;
 &lt;p&gt;   In the second case, either there is a needy guest or memory needs to be reclaimed for a
 guest which would be migrated to the machine. Both the situations are similar except
 that when memory is reclaimed for an incoming guest, there is no needy guest to be
 ballooned up. Depending on the needed memory and idle memory, three situations can
 arise.
    &lt;/p&gt;
 &lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
 1. &lt;/dt&gt;&lt;dd
 class=&#34;enumerate&#34;&gt;&lt;!--l. 167--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi mathvariant=&#34;bold&#34;&gt;TotalNeededMemory ≤ TotalSoftIdleMemory.&lt;/mi&gt;&lt;/math&gt;
    The requirements of each needy guest can be satisﬁed by just soft-ballooning.
    So, the idle guests are ballooned down to reclaim the needed memory and
    then, the needy guests are ballooned up.
    &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
 2. &lt;/dt&gt;&lt;dd
 class=&#34;enumerate&#34;&gt;&lt;!--l. 168--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi mathvariant=&#34;bold&#34;&gt;TotalSoftIdleMemory &amp;#x003C; TotalNeededMemory ≤ TotalHardIdleMemory.&lt;/mi&gt;&lt;/math&gt;
    First, all the soft idle memory is ballooned out. Then, the rest of the needed
    memory is divided among the guests with hard idle memory in proportion of
    their hard idle memory. So, memory reclaimed by hard ballooning for a guest
    is given by
    &lt;!--tex4ht:inline--&gt;&lt;!--l. 169--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
 &lt;mi&gt;NeedAfterSoftBallooning = TotalNeededMemory − TotalSoftIdleMemory&lt;/mi&gt;
 &lt;/math&gt;
    &lt;p&gt;


    &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 170--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
      &lt;mi&gt;HardReclaim =&lt;/mi&gt; &lt;mfrac&gt;&lt;mrow
 &gt;&lt;mi&gt;GuestHardIdleMem ∗ NeedAfterSoftBallooning&lt;/mi&gt;&lt;/mrow&gt;
             &lt;mrow
 &gt;&lt;mi&gt;TotalHardIdleMemory&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;
 &lt;/math&gt;
    &lt;p&gt; Here, &lt;!--l. 171--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi&gt;GuestHardIdleMem&lt;/mi&gt;&lt;/math&gt;
    is the hard idle memory for that particular guest, while &lt;!--l. 171--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi&gt;TotalHardIdleMem&lt;/mi&gt;&lt;/math&gt;
    is the total hard idle memory. The reason hard ballooning is treated diﬀerently
    from soft ballooning is because soft ballooning is not supposed to have any
    aﬀect on the performance of the guest as it takes away only the free pages. On
    the other hand, hard ballooning also reclaims some of the page caches, which
    might have some eﬀect on the performance of the guest.
    &lt;/p&gt;
 &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
 3. &lt;/dt&gt;&lt;dd
 class=&#34;enumerate&#34;&gt;&lt;!--l. 172--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;inline&#34; &gt;&lt;mi mathvariant=&#34;bold&#34;&gt;TotalNeededMemory &amp;#x003E; TotalHardIdleMemory.&lt;/mi&gt;&lt;/math&gt;
    This case implies that there is a hotspot on the host. Since the demands of
    all the guests cannot be satisﬁed, the memory is given to them or reclaimed
    from them based on their entitlement. The &lt;em&gt;&lt;span
 class=&#34;cmti-12&#34;&gt;entitled memory&lt;/span&gt;&lt;/em&gt; of each guest is
    calculated as
    &lt;!--tex4ht:inline--&gt;&lt;!--l. 173--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
 &lt;mi&gt;EntitledMemory = GuestMaximumMemory ∗ MemoryOvercommitmentRatio&lt;/mi&gt;
 &lt;/math&gt;
    &lt;p&gt; After this, the idle memory and needed memory calculation is done again.


    &lt;!--tex4ht:inline--&gt;&lt;/p&gt;
 &lt;!--l. 175--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;
            &lt;mi&gt;IdleMemory = max(CurrentMemory − EntitledMemory, 0)&lt;/mi&gt;
 &lt;/math&gt;
    &lt;p&gt;
 &lt;/p&gt;
 &lt;div class=&#34;math-display&#34;&gt;&lt;!--l. 176--&gt;&lt;math
 xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
 display=&#34;block&#34; &gt;&lt;mrow
 &gt;
 &lt;mi&gt;NeededMemory =  &lt;/mi&gt;&lt;mfenced separators=&#34;&#34;
 open=&#34;{&#34;  close=&#34;&#34; &gt;&lt;mrow&gt; &lt;mtable  align=&#34;axis&#34; style=&#34;&#34;  
 equalrows=&#34;false&#34; columnlines=&#34;none&#34; equalcolumns=&#34;false&#34; class=&#34;array&#34;&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mi&gt;0&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;if &lt;/mtext&gt;&lt;mstyle
 class=&#34;math&#34;&gt;&lt;mi&gt;!isNeedy(guest)&lt;/mi&gt;&lt;/mstyle&gt;&lt;mtext  &gt;&lt;/mtext&gt;&lt;/mstyle&gt;                                     &lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;
 &lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mi&gt;0&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mi&gt;CurrentMemory &amp;#x003E; EntitledMemory          &lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;
 &lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mi&gt;min(0.1 ∗ CurrentMemory,                      &lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;
 &lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mi&gt;CurrentMemory − EntitledMemory)&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mstyle
 class=&#34;text&#34;&gt;&lt;mtext  &gt;otherwise&lt;/mtext&gt;&lt;/mstyle&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd
 class=&#34;array&#34;  columnalign=&#34;left&#34;&gt;&lt;mspace width=&#34;1em&#34; class=&#34;quad&#34;/&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;!--@{}l@{\quad }l@{}--&gt;&lt;/mtable&gt;                                              &lt;/mrow&gt;&lt;/mfenced&gt;
 &lt;/mrow&gt;&lt;/math&gt;&lt;/div&gt;
    &lt;p&gt; Then, the idle memory is ballooned out of the guests and the needed memory
    is provided to the needy guests.
 &lt;a
 id=&#34;Q1-9-56&#34;&gt;&lt;/a&gt;
    &lt;/p&gt;

    &lt;h4 class=&#34;likesubsectionHead&#34;&gt;&lt;a
 href=&#34;#x9-510003&#34; id=&#34;x9-510003&#34;&gt;Summary&lt;/a&gt;&lt;/h4&gt;
    &lt;p&gt;In this chapter, we looked at the diﬀerent techniques we use to monitor various
    metrics for hosts and guests. These metrics are used to trigger hotspot and
    make  the  ballooning  service  active.  We  also  looked  at  the  CUSUM  based
    algorithm used to ﬁlter out unecessary spikes in the resource usage proﬁles of
    the host. In the end, we also discussed our technique of autoballooning.&lt;/p&gt;
 &lt;/dd&gt;&lt;/dl&gt;


 &lt;!--l. 1--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
 href=&#34;mainch5.html&#34; &gt;next&lt;/a&gt;] [&lt;a
 href=&#34;mainch3.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
 href=&#34;mainch3.html#tailmainch3.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
 href=&#34;mainch4.html&#34; &gt;front&lt;/a&gt;] [&lt;a
 href=&#34;main.html#mainch4.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
 &lt;p&gt;   &lt;a
 id=&#34;tailmainch4.html&#34;&gt;&lt;/a&gt;             &lt;/p&gt;

 

</description>
    </item>
    
    <item>
      <title>Introduction: Virtualization and Resource Management in Cloud</title>
      <link>http://www.ninjaducks.in/thesis/mainch1.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainch1.html</guid>
      <description>
&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch2.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainli4.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainli4.html#tailmainli4.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;#tailmainch1.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch1.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;h2 class=&#34;chapterHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;Chapter 1&lt;/span&gt;&lt;br /&gt;&lt;a
href=&#34;main.html#QQ2-6-7&#34; id=&#34;x6-50001&#34;&gt;Introduction: Virtualization and Resource Management in Cloud&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the advent of large scale cloud computing, the users can get compute resources on
demand with ﬂexible pricing models. Cloud vendors pool their massive hardware
resources and provide virtual machines on top of it to the users. To best utilize the
resources of a virtualized cloud infrastructure, resource overcommitment is used.
Allocating more virtual resources to a machine or a group of machines than are physically
present is called resource overcommitment.
&lt;/p&gt;
&lt;p&gt;   Since most applications will not use all of the resources allocated to them at all the
times, most of the resources of a cloud provider will remain idle without overcommitment.
Hence, this approach is more proﬁtable and less wasteful. Orthogonal to overcommitment
is the fact that cloud vendors have to satisfy some SLAs (Service Level Agreements)
which they have with the users i.e. the promised resources should be available to the
users whenever they need it. Distributed resource scheduling (DRS) is used to meet these
SLAs.
&lt;/p&gt;
&lt;p&gt;   Apart from the public cloud oﬀerings like Amazon Web Services and Microsoft
Azure, many companies and educational institutions are virtualizing their IT
infrastructure to create private clouds. Private clouds may have less strict SLA&amp;#x2019;s but
require resource scheduling to enhance performance of the virtual machines.
Overcommitment without resource management may lead to degradation in
performance.
&lt;a
id=&#34;x6-5001r1&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;1.1   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-6-8&#34; id=&#34;x6-60001&#34;&gt;Virtualization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Virtualization is one of the driving technologies behind IaaS (Infrastructure as a Service).
Virtualization makes it possible to run multiple operating systems with diﬀerent
conﬁgurations on a physical machine at the same time.
&lt;/p&gt;
&lt;p&gt;   To run virtual machines on a system, a software layer called hypervisor or virtual


machine monitor (VMM) is required. The hypervisor has the control of all the hardware
resources and can take away resources from one VM to give it to another. The hypervisor
also maintains the state of all the VMs at all the times. It does these by trapping all the
privileged instructions executed by the guest VM and emulating the resource they access.
The hypervisor is responsible for emulating all the hardware devices and providing
proper resource isolation between multiple machines running on the same physical
machine.
&lt;/p&gt;
&lt;p&gt;   There are three diﬀerent techniques used for virtualization [&lt;a id=&#34;page.4&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-horne2007understanding&#34; &gt;1&lt;/a&gt;] which mainly
diﬀer in the way they trap the privileged instructions executed by the guest
kernel.
   &lt;/p&gt;
&lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
1. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Full Virtualization with Binary Translation.&lt;/span&gt;&lt;/strong&gt; In this approach, user mode
   code runs directly on CPU without any translation, but the non-virtualizable
   instructions [&lt;a
href=&#34;mainli5.html#X0-Popek:1974:FRV:361011.361073&#34; &gt;2&lt;/a&gt;] in the guest kernel code are translated on the ﬂy to code which
   has the intended eﬀect on the virtual hardware.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
2. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Hardware Assisted Full Virtualization.&lt;/span&gt;&lt;/strong&gt;To make virtualization simpler,
   hardware vendors have developed new features in the hardware to support
   virtualization.  Intel  VT-x  and  AMD-V  are  two  technologies  developed  by
   Intel and AMD respectively which provide special instructions in their ISA
   (Instruction Set Architecture) for virtual machines and a new ring privilege
   level for VM. Privileged and sensitive calls are set to automatically trap to the
   VMM, removing the need for either binary translation or paravirtualization.
   It also has modiﬁed MMU with support for multi level page tables [&lt;a
href=&#34;mainli5.html#X0-bhargava2008accelerating&#34; &gt;3&lt;/a&gt;] and
   tagged TLBs.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
3. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Paravirtualization.&lt;/span&gt;&lt;/strong&gt; This technique requires modiﬁcation of the guest kernel.
   The non-virtualizable/privileged instructions in the source code of the guest
   kernel are replaced with hypercalls which directly call the hypervisor [&lt;a
href=&#34;mainli5.html#X0-barham2003xen&#34; &gt;4&lt;/a&gt;]. The


   hypervisor  provides  hypercall  interfaces  for  kernel  operations  like  memory
   management, interrupt handling, and communication to devices. It diﬀers from
   full virtualization, where unmodiﬁed guest kernel is used and the guest OS
   does not know that it is running in a virtualized environment.&lt;/dd&gt;&lt;/dl&gt;
&lt;p&gt;   Hypervisors can be bare-metal hypervisors or hosted hypervisors. A Bare-metal
hypervisor runs directly on the physical hardware while the hosted hypervisor runs on top
of conventional operating systems. There are several hypervisors available in the market
with VMWare ESX and Xen [&lt;a id=&#34;page.5&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-barham2003xen&#34; &gt;4&lt;/a&gt;] being the popular bare-metal hypervisors, while
KVM-QEMU [&lt;a
href=&#34;mainli5.html#X0-kivity2007kvm&#34; &gt;5&lt;/a&gt;, &lt;a
href=&#34;mainli5.html#X0-bellard2005qemu&#34; &gt;6&lt;/a&gt;] being a popular hosted hypervisor which runs on top of the Linux
operating system. KVM is a kernel module providing support for hardware assited
virtualization in Linux while, QEMU is a userspace emulator. KVM uses QEMU mainly
for emulating the hardware [&lt;a
href=&#34;mainli5.html#X0-Habib:2008:VK:1344209.1344217&#34; &gt;7&lt;/a&gt;]. So, both these pieces of software work together as a
complete hypervisor for linux. KVM-QEMU and Xen are open source while ESX is
proprietary. For the purpose of this thesis, we will refer to KVM-QEMU wherever
hypervisor is used unless speciﬁed otherwise.
&lt;/p&gt;
&lt;p&gt;   Virtualization provides a number of beneﬁts other than resource isolation, which
makes it the fundamental technology behind IaaS.
   &lt;/p&gt;
&lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
1. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;It provides the ability to treat disks of virtual machine as ﬁles which can be
   easily snapshotted for backup and restore.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
2. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;It provides ease of creation of new machines and deployment of applications
   through pre-built images of the ﬁlesystem of the machine.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
3. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;Virtual machines can be easily migrated or relocated if the physical machines
   may require maintenance or develop some failure.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
4. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;Ease in increasing the resource capacity (RAM or CPU cores) of the machine


   at runtime by CPU or memory hotplug [&lt;a
href=&#34;mainli5.html#X0-Hansen_hotplugmemory&#34; &gt;8&lt;/a&gt;], or otherwise.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
5. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;Since  the  hardware  resources  are  emulated  by  the  hypervisor,  there  is  an
   opportunity for overcommitment of CPU and memory resources here.&lt;/dd&gt;&lt;/dl&gt;
&lt;a
id=&#34;x6-6009r1&#34;&gt;&lt;/a&gt;
&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;1.1.1   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-6-9&#34; id=&#34;x6-70001&#34;&gt;Memory Overcommitment and Ballooning&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;In memory overcommitment, more memory is allocated to the virtual machines(VM) than
is physically present in hardware. This is possible because hypervisors allocate memory to
the virtual machines on demand. KVM-QEMU treats all the running VMs as
processes of the host system and uses malloc to allocate memory for a VM&amp;#x2019;s RAM.
Linux uses demand paging for its processes, so a VM on bootup will allocate
only the amount of memory required by it for booting up, and not its whole
capacity.
&lt;/p&gt;
&lt;p&gt;   On demand memory allocation in itself is not enough to make memory overcommitment a
viable option. There is no way for the hypervisor to free a memory page that has been
freed by the guest OS. Hence a page once allocated to a VM always remains allocated.
The hypervisor should be able to reclaim free memory from the guest machines, otherwise
the memory consumption of guest machines will always keep on increasing till
they use up all their memory capacity. If the memory is overcommited, all the
guests trying to use their maximum capacity will lead to swapping and very poor
performance.
&lt;/p&gt;
&lt;p&gt;   There exists a mechanism called &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;memory ballooning&lt;/span&gt;&lt;/em&gt; to reclaim free memory from
guest machines. This is possible through a device driver that exists in guest
operating system and a backend virtual device in the hypervisor which talks to that
device driver. The balloon driver takes a target memory from the balloon device.
If the target memory is less than the current memory of the VM, it allocates
&lt;!--l. 62--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mrow &gt;&lt;mo
class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
&gt;c&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;g&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt; pages
from the machine and gives them back to the hypervisor. This process is called balloon


inﬂation. If the target memory is more than the current memory, the balloon driver frees
required pages from the balloon. This process is called balloon deﬂation. Memory
ballooning is an opportunistic reclamation technique and does not guarantee reclamation.
The hypervisor has limited control over the success of reclamation and the amount of
memory reclaimed, as it depends on the balloon driver which is loaded inside the guest
operating system.
&lt;/p&gt;
&lt;p&gt;   The Memory ballooning technique leverages modiﬁed guest kernel as it uses an extra
device driver and hence falls under Paravirtualization. But the virtio balloon driver [&lt;a id=&#34;page.7&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-russell2008virtio&#34; &gt;9&lt;/a&gt;]
exists in the linux source code since version 2.6 and a backend balloon device exists in
QEMU to facilitate ballooning. The virtio drivers can be installed additionally in a
Windows system.
&lt;a
id=&#34;x6-7001r9&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;1.1.2   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-6-10&#34; id=&#34;x6-80002&#34;&gt;CPU Overcommitment&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;CPU overcommitment happens through time sharing of CPU cores on a physical
machine by multiple VMs. The virtual CPU cores for a VM are called vCPU.
Most hypervisors allow multiple virtual machines to share same physical CPU
core for multiple vCPUs. QEMU-KVM runs one vCPU thread per guest CPU
[&lt;a
href=&#34;mainli5.html#X0-qemu-multi&#34; &gt;10&lt;/a&gt;]. The thread scheduling onto physical CPU is handled by the host operating
system. Time sharing CPU cores can incur a performance penalty, which is
measured by the time a vCPU spends in the ready queue, i.e. the time for which a
vCPU is ready to be scheduled but does not get scheduled. This time is called
the &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;steal time&lt;/span&gt;&lt;/em&gt; as it represents the CPU cycles that have been stolen from the
vCPU. If the guests on a host experience high steal, the CPU of the host is
overloaded.
&lt;a
id=&#34;x6-8001r8&#34;&gt;&lt;/a&gt;
&lt;/p&gt;



&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;1.2   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-6-11&#34; id=&#34;x6-90002&#34;&gt;Virtual Machine Live Migration&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;VM live migration [&lt;a
href=&#34;mainli5.html#X0-Clark:2005:LMV:1251203.1251223&#34; &gt;11&lt;/a&gt;] is a technique to migrate a running VM from one host to another
without shutting it down. Live migration involves migrating the disk, memory and CPU
states of the running VM to the destination host and resuming the VM there. Migrating
disk can be as easy as just copying the disk to destination or using a ﬁle-system shared
over the network like Network File System (NFS). There are two popular techniques for
migrating the VM memory and state:
   &lt;/p&gt;
&lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
1. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Pre-Copy Live Migration.&lt;/span&gt;&lt;/strong&gt; It follows an iterative page copying technique
   wherein ﬁrst, all the pages of the VM are copied to the destination. From
   next iteration onward, only the pages which were dirtied during the previous
   iteration are copied to the destination. This process continues till the page
   dirtying speed is less than the page transfer speed. Then the VM at the source
   is stopped, remaining dirty pages and VM state is copied to the destination,
   and the VM is resumed at the destination. QEMU-KVM uses pre-copy live
   migration [&lt;a id=&#34;page.8&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-qemu-migration&#34; &gt;12&lt;/a&gt;].
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
2. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Post-Copy Live Migration.&lt;/span&gt;&lt;/strong&gt; The VM is stopped at the source, its state
   is copied to the destination, and the VM resumed there. The pages of the
   VM are transferred to the destination in background, with the pages that are
   immediately demanded by the VM via page fault given the highest priority in
   transfer. Thus, the performance of the VM is degraded before its working set
   is transferred.&lt;/dd&gt;&lt;/dl&gt;
&lt;p&gt;   The migration time of a VM is the time taken to resume the VM on the
destination after triggering the migration. There is also a small amount of downtime
involved in live migration in which the VM is neither running on the host, nor on
the destination. Live migration of VMs connected to a network is especially
tricky because the new VM has to assigned the same IP address and all the


packets have to rerouted to the new destination without any delay to prevent
packet loss and downtime of any service running inside the VM which uses the
network.
&lt;/p&gt;
&lt;div class=&#34;table&#34;&gt;


&lt;p&gt;   &lt;a
id=&#34;x6-9003r1&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&#34;float&#34; /&gt;&lt;div class=&#34;float&#34;
&gt;


&lt;a
id=&#34;x6-9004&#34;&gt;&lt;/a&gt;
&lt;div class=&#34;caption&#34;
&gt;&lt;span class=&#34;id&#34;&gt;Table 1.1: &lt;/span&gt;&lt;span  
class=&#34;content&#34;&gt;Diﬀerences between pre-copy and post-copy live migration&lt;/span&gt;&lt;/div&gt;&lt;!--tex4ht:label?: x6-9003r1 --&gt;
&lt;div class=&#34;center&#34;
&gt;
&lt;p&gt;
&lt;table id=&#34;TBL-4&#34; class=&#34;tabular&#34;
cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;  
&gt;&lt;colgroup id=&#34;TBL-4-1g&#34;&gt;&lt;col
id=&#34;TBL-4-1&#34; /&gt;&lt;col
id=&#34;TBL-4-2&#34; /&gt;&lt;/colgroup&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-1-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-1-1&#34;  
class=&#34;td11&#34;&gt;                             &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-2-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-2-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                             &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-3-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-3-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Pre-Copy                                 &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-3-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Post-Copy                               &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-4-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-4-1&#34;  
class=&#34;td11&#34;&gt;                              &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-5-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-5-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                             &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-6-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-6-1&#34;  
class=&#34;td11&#34;&gt;                              &lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-7-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-7-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                             &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-8-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-8-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Total  migration  time  =  (RAM
size/link  speed)  +  overhead  +
non-deterministic (depending on
dirtying pattern)                       &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-8-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Total migration Time = (RAM
size/link speed) + overhead        &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-9-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-9-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                             &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-10-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-10-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Worst  downtime  =  (VM  state
time) + (RAM size/link speed)    &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-10-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;Worst  downtime  =  VM  state
time                                       &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-11-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-11-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                             &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-12-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-12-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;It  can  cope  with  network  or
system failure.                          &lt;/p&gt;
&lt;/td&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-12-2&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;In  case  of  network  or  system
failure, VM cannot be recovered.  &lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr
class=&#34;hline&#34;&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;td&gt;&lt;hr /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr  
style=&#34;vertical-align:baseline;&#34; id=&#34;TBL-4-13-&#34;&gt;&lt;td  style=&#34;text-align:left;&#34; id=&#34;TBL-4-13-1&#34;  
class=&#34;td11&#34;&gt; &lt;p&gt;                             &lt;/p&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;


&lt;/div&gt;&lt;hr class=&#34;endfloat&#34; /&gt;
&lt;/div&gt;
&lt;a
id=&#34;x6-9005r11&#34;&gt;&lt;/a&gt;
&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;1.3   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-6-12&#34; id=&#34;x6-100003&#34;&gt;Resource Management in Cloud&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Resource management is an essential technique to utilize the underlying hardware of the
cloud eﬃciently. The role of the resource manager is to manage the allocation of physical
resources to the virtual machines deployed on a cluster of nodes in a cloud. Diﬀerent
resource management systems may have diﬀerent aims depending upon the needs. For a
private cloud like in an educational institution, the most common aim might be to
maximize performance of the virtual machines while minimizing the operational costs of
the cloud infrastructure.
&lt;/p&gt;
&lt;p&gt;   Minimizing operational costs involves minimizing the number of physical machines
used. This can be achieved through overcommitment of resources. Resource
overcommitment comes with some new problems like hotspot elimination and where to
schedule new incoming VMs to minimize chances of hotspot. If the total capacity of the
virtual machines running on a physical machine is more than the total capacity of the
physical machines, a situation may arise wherein the VMs may want to use a sum total of
more resources than are present. Not satisfying those resource requirements may lead to
violation of SLAs and poor performance of the VMs. This situation is called a hotspot. A
distributed resource scheduler (DRS) is a piece of software that runs on diﬀerent nodes in
the cluster and handles dynamic resource allocation to diﬀerent VMs in the
cluster.
&lt;/p&gt;
&lt;p&gt;   Memory ballooning and live migration of VM can help in mitigating hotspots. The
basic idea is that if a VM is short on memory, ballooning can be used to take away some
memory from another guest on the same host which has some free memory and give it to
the needy guest. If none of the guests have any free memory, the host is overloaded. A
guest has to be migrated from this host to another host while taking into account the
overall load of the cluster. This might sound simple, but there are several challenges


involved in this process. Some of the challenges are determining the amount of free
memory a VM can give away without aﬀecting its own performance, determining whether
beneﬁts of migration are more than performance loss, selecting which virtual
machine to migrate such that maximum beneﬁt is achieved out of the migration,
selecting destination host to minimize the chances of future migrations, ﬁltering
intermittent spikes from resource usage graph of VMs to determine their actual load
proﬁle and distributed monitoring of VMs which can scale to a large number of
machines. In this thesis, we address large scale monitoring and ballooning of virtual
machines.
&lt;a
id=&#34;x6-10001r12&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;1.4   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-6-13&#34; id=&#34;x6-110004&#34;&gt;Organization of this Thesis &lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The rest of the thesis is organized as follows. Chapter 2 describes related work that has
been done in this area. Chapter 3 consolidates the requirements of a DRS, outlines our
approach to building the DRS, and proposes a decentralized and scalable architecture for
it. Chapter 4 describes the details of implementation of the monitoring and
autoballooning components of our DRS. Chapter 5 analyses the monitoring and
autoballooning components of the DRS through experimental data. Finally, Chapter 6
concludes the work done in this thesis and provides some insights on possible extensions
to this work.
&lt;a
id=&#34;Q1-6-14&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;likesubsectionHead&#34;&gt;&lt;a
href=&#34;#x6-120004&#34; id=&#34;x6-120004&#34;&gt;Summary&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;In this chapter, we discussed the diﬀerent technologies behind cloud computing and
looked at how they are used. We have looked at how resource overcommitment helps in
utilizing the hardware eﬃciently and why resource management is essential for
overcommitment to work. We have also identiﬁed several problems and challenges related
to resource management which have been resolved in this thesis.


&lt;/p&gt;
&lt;!--l. 1--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch2.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainli4.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainli4.html#tailmainli4.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;mainch1.html&#34; &gt;front&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch1.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;   &lt;a
id=&#34;tailmainch1.html&#34;&gt;&lt;/a&gt;        &lt;/p&gt;


</description>
    </item>
    
    <item>
      <title>References</title>
      <link>http://www.ninjaducks.in/thesis/mainli5.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainli5.html</guid>
      <description>
&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch6.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch6.html#tailmainch6.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;#tailmainli5.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainli5.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;h2 class=&#34;likechapterHead&#34;&gt;&lt;a
href=&#34;main.html#QQ2-2-61&#34; id=&#34;x12-660003&#34;&gt;References&lt;/a&gt;&lt;/h2&gt;
   &lt;dl class=&#34;thebibliography&#34;&gt;&lt;dt id=&#34;X0-horne2007understanding&#34; class=&#34;thebibliography&#34;&gt;
[1]  &lt;/dt&gt;&lt;dd
id=&#34;bib-1&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;&lt;a id=&#34;page.109&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html&#34; id=&#34;X0-&#34; &gt;&lt;/a&gt;Chris  Horne.  “Understanding  full  virtualization,  paravirtualization  and
   hardware assist”. In: &lt;span
class=&#34;cmti-12&#34;&gt;White paper, VMware Inc &lt;/span&gt;(2007).
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-Popek:1974:FRV:361011.361073&#34; class=&#34;thebibliography&#34;&gt;
[2]  &lt;/dt&gt;&lt;dd
id=&#34;bib-2&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Gerald  J.  Popek  and  Robert  P.  Goldberg.  “Formal  Requirements  for
   Virtualizable  Third  Generation  Architectures”.  In:  &lt;span
class=&#34;cmti-12&#34;&gt;Commun.  ACM  &lt;/span&gt;17.7
   (July 1974), pp. 412–421. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;i&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;s&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;s&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;n&lt;/span&gt;&lt;/span&gt;: 0001-0782. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;d&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;o&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;i&lt;/span&gt;&lt;/span&gt;: &lt;a
href=&#34;http://dx.doi.org/10.1145/361011.361073&#34; &gt;10.1145/361011.361073&lt;/a&gt;. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;http://doi.acm.org/10.1145/361011.361073&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;http://doi.acm.org/10.1145/361011.361073&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-bhargava2008accelerating&#34; class=&#34;thebibliography&#34;&gt;
[3]  &lt;/dt&gt;&lt;dd
id=&#34;bib-3&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Ravi Bhargava, Benjamin Serebrin, Francesco Spadini, and Srilatha Manne.
   “Accelerating two-dimensional page walks for virtualized systems”. In: &lt;span
class=&#34;cmti-12&#34;&gt;ACM&lt;/span&gt;
   &lt;span
class=&#34;cmti-12&#34;&gt;SIGOPS Operating Systems Review &lt;/span&gt;42.2 (2008), pp. 26–35.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-barham2003xen&#34; class=&#34;thebibliography&#34;&gt;
[4]  &lt;/dt&gt;&lt;dd
id=&#34;bib-4&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Paul Barham, Boris Dragovic, Keir Fraser, Steven Hand, Tim Harris, Alex
   Ho, Rolf Neugebauer, Ian Pratt, and Andrew Warﬁeld. “Xen and the art
   of virtualization”. In: &lt;span
class=&#34;cmti-12&#34;&gt;ACM SIGOPS Operating Systems Review &lt;/span&gt;37.5 (2003),
   pp. 164–177.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-kivity2007kvm&#34; class=&#34;thebibliography&#34;&gt;
[5]  &lt;/dt&gt;&lt;dd
id=&#34;bib-5&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Avi Kivity, Yaniv Kamay, Dor Laor, Uri Lublin, and Anthony Liguori. “kvm:
   the Linux virtual machine monitor”. In: &lt;span
class=&#34;cmti-12&#34;&gt;Proceedings of the Linux symposium&lt;/span&gt;.
   Vol. 1. 2007, pp. 225–230.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-bellard2005qemu&#34; class=&#34;thebibliography&#34;&gt;
[6]  &lt;/dt&gt;&lt;dd
id=&#34;bib-6&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Fabrice  Bellard.  “QEMU,  a  Fast  and  Portable  Dynamic  Translator.”  In:
   &lt;span
class=&#34;cmti-12&#34;&gt;USENIX Annual Technical Conference, FREENIX Track&lt;/span&gt;. 2005, pp. 41–46.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-Habib:2008:VK:1344209.1344217&#34; class=&#34;thebibliography&#34;&gt;
[7]  &lt;/dt&gt;&lt;dd
id=&#34;bib-7&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Irfan Habib. “Virtualization with KVM”. In: &lt;span
class=&#34;cmti-12&#34;&gt;Linux J. &lt;/span&gt;2008.166 (Feb. 2008).
   &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;i&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;s&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;s&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;n&lt;/span&gt;&lt;/span&gt;:                                     1075-3583.                                     &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;http://dl.acm.org/citation.cfm?id=1344209.1344217&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;http://dl.acm.org/citation.cfm?id=1344209.1344217&lt;/span&gt;&lt;/a&gt;.


   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-Hansen_hotplugmemory&#34; class=&#34;thebibliography&#34;&gt;
[8]  &lt;/dt&gt;&lt;dd
id=&#34;bib-8&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Dave Hansen, Mike Kravetz, Brad Christiansen, and Matt Tolentino. “Hotplug
   memory and the linux vm”. In: &lt;span
class=&#34;cmti-12&#34;&gt;In Linux Symposium&lt;/span&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-russell2008virtio&#34; class=&#34;thebibliography&#34;&gt;
[9]  &lt;/dt&gt;&lt;dd
id=&#34;bib-9&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Rusty Russell. “virtio: towards a de-facto standard for virtual I/O devices”.
   In: &lt;span
class=&#34;cmti-12&#34;&gt;ACM SIGOPS Operating Systems Review &lt;/span&gt;42.5 (2008), pp. 95–103.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-qemu-multi&#34; class=&#34;thebibliography&#34;&gt;
[10]  &lt;/dt&gt;&lt;dd
id=&#34;bib-10&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Anthony Liguori. “Multi-threading QEMU”. In: &lt;span
class=&#34;cmti-12&#34;&gt;KVM Forum&lt;/span&gt;. &lt;a
href=&#34;http://www.linux-kvm.org/images/7/70/2010-forum-threading-qemu.pdf&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;http://www.linux-kvm.org/images/7/70/2010-forum-threading-qemu.pdf&lt;/span&gt;&lt;/a&gt;.
   Aug. 2010.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-Clark:2005:LMV:1251203.1251223&#34; class=&#34;thebibliography&#34;&gt;
[11]  &lt;/dt&gt;&lt;dd
id=&#34;bib-11&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Christopher  Clark,  Keir  Fraser,  Steven  Hand,  Jacob  Gorm  Hansen,  Eric
   Jul, Christian Limpach, Ian Pratt, and Andrew Warﬁeld. “Live Migration
   of Virtual Machines”. In: &lt;span
class=&#34;cmti-12&#34;&gt;Proceedings of the 2Nd Conference on Symposium&lt;/span&gt;
   &lt;span
class=&#34;cmti-12&#34;&gt;on  Networked  Systems  Design  &amp;#x0026;  Implementation  -  Volume  2&lt;/span&gt;.  NSDI&amp;#x2019;05.
   Berkeley,   CA,   USA:   USENIX   Association,   2005,   pp.   273–286.   &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;http://dl.acm.org/citation.cfm?id=1251203.1251223&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;http://dl.acm.org/citation.cfm?id=1251203.1251223&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-qemu-migration&#34; class=&#34;thebibliography&#34;&gt;
[12]  &lt;/dt&gt;&lt;dd
id=&#34;bib-12&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;&lt;span
class=&#34;cmti-12&#34;&gt;KVM-Migration&lt;/span&gt;.               Accessed:               2016-05-09.               &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;http://www.linux-kvm.org/page/Migration&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;http://www.linux-kvm.org/page/Migration&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-magenheimer2009transcendent&#34; class=&#34;thebibliography&#34;&gt;
[13]  &lt;/dt&gt;&lt;dd
id=&#34;bib-13&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Dan  Magenheimer,  Chris  Mason,  Dave  McCracken,  and  Kurt  Hackel.
   “Transcendent memory and linux”. In: &lt;span
class=&#34;cmti-12&#34;&gt;Proceedings of the Linux Symposium&lt;/span&gt;.
   2009, pp. 191–200.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-waldspurger2002memory&#34; class=&#34;thebibliography&#34;&gt;
[14]  &lt;/dt&gt;&lt;dd
id=&#34;bib-14&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Carl A Waldspurger. “Memory resource management in VMware ESX server”.
   In: &lt;span
class=&#34;cmti-12&#34;&gt;ACM SIGOPS Operating Systems Review &lt;/span&gt;36.SI (2002), pp. 181–194.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-ksm&#34; class=&#34;thebibliography&#34;&gt;
[15]  &lt;/dt&gt;&lt;dd
id=&#34;bib-15&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Linux   Kernel   Documentation   -   vm/ksm&lt;/span&gt;.   Accessed:   2016-05-09.   &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;https://www.kernel.org/doc/Documentation/vm/ksm.txt&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;https://www.kernel.org/doc/Documentation/vm/ksm.txt&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-gulati2012vmware&#34; class=&#34;thebibliography&#34;&gt;
[16]  &lt;/dt&gt;&lt;dd
id=&#34;bib-16&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Ajay  Gulati,  Anne  Holler,  Minwen  Ji,  Ganesha  Shanmuganathan,  Carl
   Waldspurger, and Xiaoyun Zhu. “Vmware distributed resource management:
   Design, implementation, and lessons learned”. In: &lt;span
class=&#34;cmti-12&#34;&gt;VMware Technical Journal&lt;/span&gt;
   1.1 (2012), pp. 45–64.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-wood2009sandpiper&#34; class=&#34;thebibliography&#34;&gt;
[17]  &lt;/dt&gt;&lt;dd
id=&#34;bib-17&#34; class=&#34;thebibliography&#34;&gt;


   &lt;p&gt;Timothy Wood, Prashant Shenoy, Arun Venkataramani, and Mazin Yousif.
   “Sandpiper:  Black-box  and  gray-box  resource  management  for  virtual
   machines”. In: &lt;span
class=&#34;cmti-12&#34;&gt;Computer Networks &lt;/span&gt;53.17 (2009), pp. 2923–2938.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-mishra2011theory&#34; class=&#34;thebibliography&#34;&gt;
[18]  &lt;/dt&gt;&lt;dd
id=&#34;bib-18&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Mayank  Mishra  and  Anirudha  Sahoo.  “On  theory  of  vm  placement:
   Anomalies in existing methodologies and their mitigation using a novel vector
   based approach”. In: &lt;span
class=&#34;cmti-12&#34;&gt;Cloud Computing (CLOUD), 2011 IEEE International&lt;/span&gt;
   &lt;span
class=&#34;cmti-12&#34;&gt;Conference on&lt;/span&gt;. IEEE. 2011, pp. 275–282.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-shen2011cloudscale&#34; class=&#34;thebibliography&#34;&gt;
[19]  &lt;/dt&gt;&lt;dd
id=&#34;bib-19&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Zhiming   Shen,   Sethuraman   Subbiah,   Xiaohui   Gu,   and   John   Wilkes.
   “Cloudscale:  elastic  resource  scaling  for  multi-tenant  cloud  systems”.  In:
   &lt;span
class=&#34;cmti-12&#34;&gt;Proceedings of the 2nd ACM Symposium on Cloud Computing&lt;/span&gt;. ACM. 2011,
   p. 5.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-tan2011exploiting&#34; class=&#34;thebibliography&#34;&gt;
[20]  &lt;/dt&gt;&lt;dd
id=&#34;bib-20&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Jian Tan, Parijat Dube, Xiaoqiao Meng, and Li Zhang. “Exploiting resource
   usage patterns for better utilization prediction”. In: &lt;span
class=&#34;cmti-12&#34;&gt;Distributed Computing&lt;/span&gt;
   &lt;span
class=&#34;cmti-12&#34;&gt;Systems  Workshops  (ICDCSW),  2011  31st  International  Conference  on&lt;/span&gt;.
   IEEE. 2011, pp. 14–19.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-singh2008server&#34; class=&#34;thebibliography&#34;&gt;
[21]  &lt;/dt&gt;&lt;dd
id=&#34;bib-21&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Aameek             Singh,             Madhukar             Korupolu,             and
   Dushmanta Mohapatra. “Server-storage virtualization: integration and load
   balancing in data centers”. In: &lt;span
class=&#34;cmti-12&#34;&gt;Proceedings of the 2008 ACM/IEEE conference&lt;/span&gt;
   &lt;span
class=&#34;cmti-12&#34;&gt;on Supercomputing&lt;/span&gt;. IEEE Press. 2008, p. 53.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-procfs&#34; class=&#34;thebibliography&#34;&gt;
[22]  &lt;/dt&gt;&lt;dd
id=&#34;bib-22&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Linux Kernel Documentation - ﬁlesystem/proc&lt;/span&gt;. Accessed: 2016-05-09. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;https://www.kernel.org/doc/Documentation/filesystems/proc.txt&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;https://www.kernel.org/doc/Documentation/filesystems/proc.txt&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-ehrhardt2013cpu&#34; class=&#34;thebibliography&#34;&gt;
[23]  &lt;/dt&gt;&lt;dd
id=&#34;bib-23&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Christian Ehrhardt. &lt;span
class=&#34;cmti-12&#34;&gt;CPU time accounting&lt;/span&gt;. Accessed: 2016-05-09. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;: &lt;a
href=&#34;http://sd-34470.dedibox.fr/downloads/PDF_Archive/CPU_time_accounting.pdf&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;http://sd-34470.dedibox.fr/downloads/PDF_Archive/CPU_time_accounting.pdf&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-andreolini2009dynamic&#34; class=&#34;thebibliography&#34;&gt;
[24]  &lt;/dt&gt;&lt;dd
id=&#34;bib-24&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Mauro Andreolini, Sara Casolari, Michele Colajanni, and Michele Messori.
   “Dynamic load management of virtual machines in cloud architectures”. In:
   &lt;span
class=&#34;cmti-12&#34;&gt;Cloud Computing&lt;/span&gt;. Springer, 2009, pp. 201–214.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-page1957estimating&#34; class=&#34;thebibliography&#34;&gt;
[25]  &lt;/dt&gt;&lt;dd
id=&#34;bib-25&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;ES  Page.  “Estimating  the  point  of  change  in  a  continuous  process”.  In:
   &lt;span
class=&#34;cmti-12&#34;&gt;Biometrika &lt;/span&gt;44.2 (1957), pp. 248–252.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-openstack&#34; class=&#34;thebibliography&#34;&gt;
[26]  &lt;/dt&gt;&lt;dd
id=&#34;bib-26&#34; class=&#34;thebibliography&#34;&gt;


   &lt;p&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Openstack          Website&lt;/span&gt;.           Accessed:           2016-05-09.           &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;https://www.openstack.org/&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;https://www.openstack.org/&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-etcd&#34; class=&#34;thebibliography&#34;&gt;
[27]  &lt;/dt&gt;&lt;dd
id=&#34;bib-27&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Etcd Website&lt;/span&gt;. Accessed: 2016-05-09. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;: &lt;a
href=&#34;https://coreos.com/etcd/&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;https://coreos.com/etcd/&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-etcd-ad&#34; class=&#34;thebibliography&#34;&gt;
[28]  &lt;/dt&gt;&lt;dd
id=&#34;bib-28&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Etcd         Administration&lt;/span&gt;.           Accessed:           2016-05-09.           &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;https://coreos.com/etcd/docs/latest/admin_guide.html&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;https://coreos.com/etcd/docs/latest/admin_guide.html&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-Henning:2006:SCB:1186736.1186737&#34; class=&#34;thebibliography&#34;&gt;
[29]  &lt;/dt&gt;&lt;dd
id=&#34;bib-29&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;John L. Henning. “SPEC CPU2006 Benchmark Descriptions”. In: &lt;span
class=&#34;cmti-12&#34;&gt;SIGARCH&lt;/span&gt;
   &lt;span
class=&#34;cmti-12&#34;&gt;Comput.                     Archit.                     News                       &lt;/span&gt;34.4
   (Sept. 2006), pp. 1–17. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;i&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;s&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;s&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;n&lt;/span&gt;&lt;/span&gt;: 0163-5964. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;d&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;o&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;i&lt;/span&gt;&lt;/span&gt;: &lt;a
href=&#34;http://dx.doi.org/10.1145/1186736.1186737&#34; &gt;10.1145/1186736.1186737&lt;/a&gt;. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;http://doi.acm.org/10.1145/1186736.1186737&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;http://doi.acm.org/10.1145/1186736.1186737&lt;/span&gt;&lt;/a&gt;.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt id=&#34;X0-yabusame&#34; class=&#34;thebibliography&#34;&gt;
[30]  &lt;/dt&gt;&lt;dd
id=&#34;bib-30&#34; class=&#34;thebibliography&#34;&gt;
   &lt;p&gt;Isaku Yamahata and Takahiro Hirofuchi. “Yabusame: Postcopy Live migration
   for QEmu/KVM”. In: &lt;span
class=&#34;cmti-12&#34;&gt;LinuxCon Japan&lt;/span&gt;. Accessed: 2016-05-09. June 2012. &lt;span
class=&#34;cmcsc-10x-x-120&#34;&gt;&lt;span
class=&#34;small-caps&#34;&gt;u&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;r&lt;/span&gt;&lt;span
class=&#34;small-caps&#34;&gt;l&lt;/span&gt;&lt;/span&gt;:
   &lt;a
href=&#34;https://events.linuxfoundation.org/images/stories/pdf/lcjp2012_yamahata_postcopy.pdf&#34; class=&#34;url&#34; &gt;&lt;span
class=&#34;cmtt-12&#34;&gt;https://events.linuxfoundation.org/images/stories/pdf/lcjp2012_yamahata_postcopy.pdf&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/dd&gt;&lt;/dl&gt;
&lt;a
id=&#34;Q1-12-74&#34;&gt;&lt;/a&gt;


&lt;!--l. 127--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch6.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch6.html#tailmainch6.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;mainli5.html&#34; &gt;front&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainli5.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;   &lt;a
id=&#34;tailmainli5.html&#34;&gt;&lt;/a&gt; &lt;/p&gt;


</description>
    </item>
    
    <item>
      <title>Related Work</title>
      <link>http://www.ninjaducks.in/thesis/mainch2.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.ninjaducks.in/thesis/mainch2.html</guid>
      <description>
&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch3.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainch1.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch1.html#tailmainch1.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;#tailmainch2.html&#34;&gt;tail&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch2.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;h2 class=&#34;chapterHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;Chapter 2&lt;/span&gt;&lt;br /&gt;&lt;a
href=&#34;main.html#QQ2-7-16&#34; id=&#34;x7-130002&#34;&gt;Related Work&lt;/a&gt;&lt;/h2&gt;
&lt;a
id=&#34;x7-13001r13&#34;&gt;&lt;/a&gt;
&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.1   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-7-17&#34; id=&#34;x7-140001&#34;&gt;Auto-Ballooning in Xen&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Xen is a popular open-source, bare-metal hypervisor which was developed by University
of Cambridge Computer Laboratory in 2003 and was the ﬁrst hypervisor to support
paravirtualization. Support for full vritualization was later added to it. Xen has
autoballooning feature which works via the autoballoon driver that exists in the Linux
kernel. Autoballooning implementation in our work has some key diﬀerences
to autoballooning in Xen, which have been discussed later. It is important to
understand both techniques for comparison. To understand Xen hypervisor&amp;#x2019;s method
of autoballooning, it is ﬁrst essential to understand transcendent memory in
Linux.
&lt;a
id=&#34;x7-14001r10&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.1.1   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-7-18&#34; id=&#34;x7-150001&#34;&gt;Transcendent Memory (tmem)&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Transcendent memory (tmem) [&lt;a id=&#34;page.15&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-magenheimer2009transcendent&#34; &gt;13&lt;/a&gt;] is a type of memory which the linux kernel cannot
directly enumerate, track or directly address, but helps in more eﬃcient utilization of
memory by a single kernel or load-balancing of memory between multiple kernels in a
virtualized environment.
&lt;/p&gt;
&lt;p&gt;   The implementation of tmem is divided into two parts - frontend and backend.
Frontend provides the interfaces for diﬀerent types of data which can be stored
provided by tmem to the kernel, while backend is the underlying implementation of
storage/retrieval methods. Two basic operations provided by the frontend are &amp;#x2019;put&amp;#x2019; and
&amp;#x2019;get&amp;#x2019;. If the kernel wants to save some data into tmem, it uses the &amp;#x2019;put&amp;#x2019; operation while
&amp;#x2019;get&amp;#x2019; is used to retrieve the data.
&lt;/p&gt;



&lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
href=&#34;#x7-160001&#34; id=&#34;x7-160001&#34;&gt;Tmem Frontends&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;There are two tmem frontends in the Linux kernel which cover two major types of kernel
memory - &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;anonymous pages&lt;/span&gt;&lt;/em&gt; and &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;ﬁle backed pages&lt;/span&gt;&lt;/em&gt;.
   &lt;/p&gt;
&lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
1. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Cleancache:&lt;/span&gt;&lt;/strong&gt; Cleancache is used for storing pages which are backed by ﬁles
   on a disk. A kernel can choose to reclaim such pages at the times of memory
   pressure. These pages are evicted from memory. If the same page is to be used
   again, a page fault happens and it is fetched from the disk. Before evicting
   such a page, the kernel can choose to store it in cleancache. If the operation
   succeeds, the page can possibly be reclaimed from tmem at any later time,
   otherwise it has to be reclaimed from disk, if needed
   &lt;p&gt;Cleancache data in tmem is ephemeral i.e. tmem can choose to discard any
   cleancache data at any point of time. Later, when a kernel wants its data back
   from tmem, if tmem has already discarded that data, the kernel can fetch it
   from the disk.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
2. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Frontswap:&lt;/span&gt;&lt;/strong&gt; Frontswap is used for storing swap pages. Linux swap subsystem
   stores  anonymous  pages  in  a  swap  device  when  it  needs  to  evict  them.
   Whenever the swap subsystem of the Linux kernel wants to swap a page to
   swap device, it can send the page to tmem instead. If the operation succeeds,
   the page is written to tmem, otherwise it goes to the swap device. Frontswap
   provides a guarantee that a page stored in it can be reclaimed at any later
   point of time, and it will not be discarded.&lt;/dd&gt;&lt;/dl&gt;
&lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
href=&#34;#x7-170001&#34; id=&#34;x7-170001&#34;&gt;Tmem Backends&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;There are multiple backends for tmem - &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;zcache&lt;/span&gt;&lt;/em&gt;, &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;transcendent memory for Xen&lt;/span&gt;&lt;/em&gt;, and
&lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;RAMster&lt;/span&gt;&lt;/em&gt;. Tmem was originally developed for Xen with Xen backend. The other backends
were created later. For autoballooning, we are only concerned with the Xen
backend.


&lt;/p&gt;
&lt;p&gt;   Tmem backend for Xen works in a virtualized environemnt under the Xen hypervisor
to share the spare hypervisor memory amongst the running VMs. In a virtualized
environment, the memory is allocated to the running VMs on demand. Some memory is
also reserved for the hypervisor to run. Thus, it may have some free memory which is not
used by anyone nd can be used for Tmem. This will result in faster swap out/in and page
reclamation for the guests under memory pressure. This plays an important part in
autoballooning of VMs and diﬀerentiates autoballooning in KVM from Xen, as we will see
in the later sections.
&lt;/p&gt;

&lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
href=&#34;#x7-180001&#34; id=&#34;x7-180001&#34;&gt;Frontswap Self Shrinking&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;When kernel swaps out a page, it assumes that the page will go to disk and may remain
there for long time even if it is not used again as kernel assumes disk space is less costly
and abundant. But if the page has gone to frontswap, it is taking up valuable memory
which might be better used elsewhere. To resolve this problem, &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;frontswap-self-shrinking&lt;/span&gt;&lt;/em&gt; is
used. When a guest kernel is under normal memory pressure, it uses partial
swapoﬀ interface to bring the pages which were swapped to tmem back to guest&amp;#x2019;s
memory. This frees tmem for use by other guests which might be under memory
pressure.
&lt;a
id=&#34;x7-18001r18&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.1.2   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-7-22&#34; id=&#34;x7-190002&#34;&gt;Auto-Balloon Mechanism&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Autoballooning in Xen requires transcendent memory. In each guest, a autoballoon driver
is present. A thread of the driver runs periodically in some ﬁxed (conﬁgurable) time
interval which sets the target size of the guest.
&lt;/p&gt;
&lt;p&gt;


&lt;!--tex4ht:inline--&gt;&lt;/p&gt;
&lt;!--l. 35--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;block&#34; &gt;
   &lt;mi
&gt;T&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;g&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;i&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;d&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;g&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
&gt;R&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;v&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;d&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;g&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
&gt;B&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;l&lt;/mi&gt;&lt;mi
&gt;l&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;v&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;d&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;g&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt;
&lt;/math&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;   &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Committed pages&lt;/span&gt;&lt;/em&gt; are the pages which are used by some process and may reside
either in memory or swap. &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Reserved pages&lt;/span&gt;&lt;/em&gt; are the pages reserved from normal
usage by the kernel. &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Balloon reserved pages&lt;/span&gt;&lt;/em&gt; form the memory reserved by the
balloon driver to provide some extra memory for the kernel caches and some
room to grow for any process that may demand more memory in the future. It
defaults to 10% of the total memory size of the guest. If the target is less than the
current RAM, the guest is ballooned down, else it is ballooned up. There is
a hysteresis counter which represents the number of iterations it will take for
the machine to balloon down to target. So, each time self-ballooning process
runs,
&lt;!--tex4ht:inline--&gt;&lt;/p&gt;
&lt;!--l. 39--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;block&#34; &gt;
                 &lt;mi
&gt;M&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;y&lt;/mi&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow
&gt;&lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;T&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;g&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;/mrow&gt;
&lt;mrow
&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;mi
&gt;y&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt;&lt;mi
&gt;i&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt;&lt;mspace width=&#34;1em&#34; class=&#34;nbsp&#34; /&gt;&lt;mi
&gt;c&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;
&lt;/math&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;   Hysteresis counter is diﬀerent for ballooning up and down. There is also a&lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;min usable&lt;/span&gt;
&lt;span
class=&#34;cmti-12&#34;&gt;MB&lt;/span&gt;&lt;/em&gt; parameter, below which machines cannot be ballooned.
&lt;/p&gt;
&lt;p&gt;   It is important to note here that Xen autoballooning is proactive in nature. Even if
none of the guests is under memory pressure, it reclaims free/idle memory from the


guests. This may seem wasteful as the memory reclaimed when there is no memory
pressure on the host may have been better used by the original guest for page caches. But
this is compensated by the fact that the reclaimed memory, if not given to any other host,
will go to tmem, which will lead to faster swap in/out for all the guests. So, the
reclaimed memory is shared by all the guests and can be used by them depending
on the need. This kind of ballooning is not possible for KVM because there
is no tmem backend for QEMU-KVM. Thus, QEMU-KVM requires reactive
ballooning.
&lt;a
id=&#34;x7-19001r17&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.2   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-7-23&#34; id=&#34;x7-200002&#34;&gt;Memory Management in VMware ESX&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;VMware was founded in 1999 when it launched its proprietary hypervisor which used
binary translation techniques for x86 virtualization. They later released an enterprise class
bare metal hypervisor called VMware ESXi. ESX has very robust memory management
and it introduced several novel techniques as early as 2003 which are still being used and
have been implemented in other platforms. The techniques used by ESX to manage
memory [&lt;a id=&#34;page.19&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-waldspurger2002memory&#34; &gt;14&lt;/a&gt;] of its guests and facilitate memory overcommitment have been very brieﬂy
described here.
&lt;a
id=&#34;x7-20001r22&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.2.1   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-7-24&#34; id=&#34;x7-210001&#34;&gt;Memory Reclamation Techniques&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;ESX uses several memory reclamation techniques.
   &lt;/p&gt;
&lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
1. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Content-Based Page Sharing:&lt;/span&gt;&lt;/strong&gt; In a virtualized environment, several guests
   might be running common OS and some common applications which means
   that  there  would  be  lots  of  pages  having  the  same  content.  Instead  of
   keeping  separate  copies  of  these  pages  for  separate  guests,  the  duplicate
   pages are deleted and only one copy of the page is kept which is marked


   Copy-On-Write(COW). When any of the guests attempts to write to that
   page, a new copy of the page is created by the kernel which is then modiﬁed.
   &lt;p&gt;Linux kernel has KSM(Kernel Same-Page Merging) [&lt;a id=&#34;page.20&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-ksm&#34; &gt;15&lt;/a&gt;] which performs the
   same task and is used in virtualization by QEMU-KVM.
   &lt;/p&gt;
&lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
2. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Memory Ballooning:&lt;/span&gt;&lt;/strong&gt; Memory Ballooning has been explained in Section
   &lt;a
href=&#34;mainch1.html#x6-70001&#34;&gt;1.1.1&lt;!--tex4ht:ref: ballooning --&gt;&lt;/a&gt;
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
3. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Page compression:&lt;/span&gt;&lt;/strong&gt; In this case, the content of the page is compressed and
   stored. When the page is accessed, its content is decompressed.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
4. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Demand Paging:&lt;/span&gt;&lt;/strong&gt; ESX server has a swap daemon which handles hypervisor
   level swapping. The swap daemon gets the target swap levels of each VM from
   the swapping policy and selects the pages that need to be swapped.
   &lt;/dd&gt;&lt;/dl&gt;
&lt;a
id=&#34;x7-21005r24&#34;&gt;&lt;/a&gt;
&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.2.2   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-7-25&#34; id=&#34;x7-220002&#34;&gt;Memory Reclamation Policies&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The ESX server deﬁnes four memory states depending upon which it employs the memory
reclamation techniques.
   &lt;/p&gt;
&lt;dl class=&#34;enumerate&#34;&gt;&lt;dt class=&#34;enumerate&#34;&gt;
1. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;High:&lt;/span&gt;&lt;/strong&gt; More than 6% of the total memory of the hypervisor is free at this
   point. Only page sharing is employed in this state.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
2. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Soft:&lt;/span&gt;&lt;/strong&gt; Free memory is between 6% and 4%. Page sharing is active. Balloon
   driver also starts reclaiming idle memory.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;


3. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Hard:&lt;/span&gt;&lt;/strong&gt; Free memory is between 4% and 2%. The hypervisor now aggressively
   starts reclaiming memory through swapping. Page compression also becomes
   active.  So,  on  page  reclamation,  if  it  is  compressible  or  shareable,  it  is
   compressed/shared otherwise it is swapped out.
   &lt;/dd&gt;&lt;dt class=&#34;enumerate&#34;&gt;
4. &lt;/dt&gt;&lt;dd
class=&#34;enumerate&#34;&gt;&lt;strong&gt;&lt;span
class=&#34;cmbx-12&#34;&gt;Low:&lt;/span&gt;&lt;/strong&gt; Below  1%  free  memory.  Along  with  memory  reclamation,  ESX  also
   blocks any new memory allocation by any guest.&lt;/dd&gt;&lt;/dl&gt;
&lt;p&gt;   One important point of contention here is which pages and how many pages to reclaim
from each guest. For determining how much memory to reclaim from each guest, ESX
uses a share based allocation technique. After getting the amount of memory to reclaim,
it chooses the pages to reclaim randomly.
&lt;/p&gt;

&lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
href=&#34;#x7-230002&#34; id=&#34;x7-230002&#34;&gt;Share-Based Allocation&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;Under share-based allocation, each guest is allocated some number of shares for
memory. A machine is guaranteed a minimum resource fraction equal to its
fraction of the total shares in the system. So, in case of memory pressure, memory
should be revoked from the guest which has the fewest shares per allocated page.
This may lead to idle clients having large number of shares hoarding memory
unproductively while active clients having fewer shares suﬀer under memory
pressure.
&lt;/p&gt;
&lt;p&gt;   To resolve this situation, ESX imposes a tax on idle memory of guests. Thus, for a client with
&lt;!--l. 75--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;S&lt;/mi&gt;&lt;/math&gt; shares and
&lt;!--l. 75--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;P&lt;/mi&gt;&lt;/math&gt; allocated pages out of
which a fraction &lt;!--l. 75--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;f&lt;/mi&gt;&lt;/math&gt; are active,
the shares-per-page ratio &lt;!--l. 75--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;R&lt;/mi&gt;&lt;/math&gt;
is


&lt;!--tex4ht:inline--&gt;&lt;/p&gt;
&lt;!--l. 76--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;block&#34; &gt;
                           &lt;mi
&gt;R&lt;/mi&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt;           &lt;mfrac&gt;&lt;mrow
&gt;&lt;mi
&gt;S&lt;/mi&gt;&lt;/mrow&gt;
&lt;mrow
&gt;&lt;mi
&gt;P&lt;/mi&gt;&lt;mrow &gt;&lt;mo
class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mi
&gt;f&lt;/mi&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
&gt;k&lt;/mi&gt;&lt;mrow &gt;&lt;mo
class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;f&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo
class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;
&lt;/math&gt;
&lt;p&gt; where the idle page cost is &lt;!--l. 77--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;k&lt;/mi&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;mo
class=&#34;MathClass-bin&#34;&gt;∕&lt;/mo&gt;&lt;mrow &gt;&lt;mo
class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;
and tax rate &lt;!--l. 77--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;τ&lt;/mi&gt;&lt;/math&gt;
is between 0 and 1. Tax rate controls the maximum fraction of
idle pages that can be reclaimed from a VM. The default value of
&lt;!--l. 77--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;τ&lt;/mi&gt;&lt;/math&gt; is
&lt;!--l. 77--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo
class=&#34;MathClass-punc&#34;&gt;.&lt;/mo&gt;&lt;mn&gt;7&lt;/mn&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/math&gt;.
&lt;/p&gt;

&lt;h5 class=&#34;subsubsectionHead&#34;&gt;&lt;a
href=&#34;#x7-240002&#34; id=&#34;x7-240002&#34;&gt;Idle Memory Calculation&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;For calculating share per page ratio eﬀectively, idle memory calculation for each
guest is required. ESX uses statistical sampling to estimate the working
set size of each VM. At the start of the sampling period, a small number
&lt;!--l. 79--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;/math&gt;
of a VM&amp;#x2019;s pages are selected randomly using uniform distribution. Accesses
to these pages are tracked by the hypervisor by incrementing a counter
&lt;!--l. 79--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;/math&gt; on every
page access. At the end of the sampling period, the fraction of working set is estimated as
&lt;!--l. 79--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;f&lt;/mi&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
&gt;t&lt;/mi&gt;&lt;mo
class=&#34;MathClass-bin&#34;&gt;∕&lt;/mo&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;/math&gt;.
&lt;a
id=&#34;x7-24001r23&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.3   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-7-28&#34; id=&#34;x7-250003&#34;&gt;VMware Distributed Resource Management&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;VMware created DRS [&lt;a id=&#34;page.22&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-gulati2012vmware&#34; &gt;16&lt;/a&gt;] for their hypervisor which is responsible for allocation of the
physical resources to a set of virtual machines deployed in a cluster of hosts. The key
capabilities of their DRS are a hierarchical resource pool abstraction, automatic initial


placement of VM, and dynamic load balancing of VMs based on their ﬂuctuating
demands. Some of our work is inspired by VMware&amp;#x2019;s DRS and aimed at ﬁxing some of its
limitations. Hence, this section provides an appropriate background for the next
chapter.
&lt;a
id=&#34;x7-25001r25&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.3.1   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-7-29&#34; id=&#34;x7-260001&#34;&gt;Resource Model&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Each VM in VMware DRS has three resource control parameters. &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Reservation&lt;/span&gt;&lt;/em&gt; speciﬁes
a minimum guaranteed amount of a particular resource which will always be
available to the VM. &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Limit&lt;/span&gt;&lt;/em&gt; speciﬁes the maximum amount of a resource that
can be allocated to a VM. &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;Shares&lt;/span&gt;&lt;/em&gt; specify the relative importance of the VMs
similar to the shares in memory allocation of ESX described in the previous
section.
&lt;/p&gt;
&lt;p&gt;   The resources in a cluster are divided into resource pools which are used for dividing
the aggregate capacity of the cluster into a group of VMs. The resource pool forms a
hierarchical tree structure with leaves as the actual VMS. The resource pool can represent
the hierarchical structure of the oraganization.
&lt;a
id=&#34;x7-26001r29&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.3.2   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-7-30&#34; id=&#34;x7-270002&#34;&gt;DRS Algorithm&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The DRS algorithm runs every ﬁve minutes. It ﬁrst divides the resources of the cluster
amongst the resource pool in a process called &lt;em&gt;&lt;span
class=&#34;cmti-12&#34;&gt;divvying&lt;/span&gt;&lt;/em&gt;. It computes the reservation,
limit, and shares of each pool. To distribute the resources, it is important to
calculate the demand of each VM, which can be used to calculate the total
load on the cluster. The working set of a VM is used as it&amp;#x2019;s memory demand.
The working set is calculated in the way explained in Section &lt;a
href=&#34;#x7-240002&#34;&gt;2.2.2&lt;!--tex4ht:ref: working-set --&gt;&lt;/a&gt;. The CPU
demand of a VM is computed as its actual CPU consumption plus a scaled
portion of the time it was ready to execute, but it spent in the ready queue due to
contention.


&lt;/p&gt;
&lt;p&gt;
&lt;!--tex4ht:inline--&gt;&lt;/p&gt;
&lt;!--l. 92--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;block&#34; &gt;
         &lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;U&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;d&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;mi
&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;U&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;mi
&gt;s&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt;         &lt;mfrac&gt;&lt;mrow
&gt;&lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;U&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/mrow&gt;
&lt;mrow
&gt;&lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;U&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;+&lt;/mo&gt; &lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;U&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;s&lt;/mi&gt;&lt;mi
&gt;l&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/mrow&gt;&lt;/mfrac&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt; &lt;mi
&gt;C&lt;/mi&gt;&lt;mi
&gt;P&lt;/mi&gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;U&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;a&lt;/mi&gt;&lt;mi
&gt;d&lt;/mi&gt;&lt;mi
&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;
&lt;/math&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;   The divvying algorithm works by dividing the resource at the parent resource pool
amongst the children. It executes in two phases. In the initial phase, it aggregates demand
values of the VMs from leaves up to the root. At each step, the demand values are
updated to be not less than the reservation and not more than the limit. The second
phase proceeds in a top-down manner and resources (limit and reservation) of
parents at each level are divided such that they are in proportion to shares of the
siblings.
&lt;/p&gt;
&lt;p&gt;   After divvying, the DRS load-balances the cluster based on a metric called
dynamic entitlement. Dynamic entitlement is equal to the demand of the VMs if
demands of each VM in the cluster can be met, otherwise it is a scaled down
value of a VMs demand based on its shares. It is computed by running the
divvying algorithm at the resource pool tree using the cluster capacity as the
resource. Then, normalized entitlement is calculated for each host. For a host
&lt;!--l. 96--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/math&gt;, normalized
entitlement &lt;!--l. 96--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/math&gt;
is deﬁned as the sum of per VM entitlement of all VMs running on
&lt;!--l. 97--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/math&gt;
divided by the host capacity.


&lt;!--tex4ht:inline--&gt;&lt;/p&gt;
&lt;!--l. 98--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;block&#34; &gt;
                                &lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mi
&gt;Σ&lt;/mi&gt; &lt;mfrac&gt;&lt;mrow
&gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/mrow&gt;
&lt;mrow
&gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/mrow&gt;&lt;/mfrac&gt;
&lt;/math&gt;
&lt;p&gt; &lt;!--l. 99--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/math&gt; values are
per-resource. &lt;!--l. 99--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;&amp;#x003C;&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;
signiﬁes that the host has some unused capacity for that resource, while
&lt;!--l. 99--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;&amp;#x003E;&lt;/mo&gt; &lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt; means
that it is overloaded for that resource. The DRS then calculates the cluster wide imbalance
&lt;!--l. 99--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;I&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/math&gt;
as the weighted sum of the standard deviation of all
&lt;!--l. 99--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/math&gt; values
for CPU and memory resources. If memory is highly contested, it&amp;#x2019;s weight is
more. If CPU is highly contested, CPU&amp;#x2019;s weight is more. If none are highly
contested, both have equal weights. The higher weighted resource gets a weight of
&lt;!--l. 99--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;h&lt;/mi&gt;&lt;mi
&gt;r&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;/math&gt; while the lower weighted
resource gets a weight of &lt;!--l. 99--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;n&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;/math&gt;.
These values were decided by experimentation.
&lt;/p&gt;
&lt;p&gt;   The DRS then tries to minimize the cluster wide imbalance
&lt;!--l. 101--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;I&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/math&gt;
by considering all possible VM migrations (trying out all possible guest VM ,
destination host pairs). The best VM migration is selected, applied to clusters state,
and another move is selected. This process continues till no beneﬁcial moves
remain, or enough moves have been selected for this pass, or the cluster imbalance
&lt;!--l. 101--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;msub&gt;&lt;mrow
&gt;&lt;mi
&gt;I&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow
&gt;&lt;mi
&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub
&gt;&lt;/math&gt; is
below a threshold. Additionally, DRS also does a cost-beneﬁt analysis of each move where


it ﬁlters out the moves with higher migration cost than beneﬁt in terms of decreasing load
imbalance.
&lt;a
id=&#34;x7-27001r30&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;subsectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.3.3   &lt;/span&gt; &lt;a
href=&#34;mainli2.html#QQ2-7-31&#34; id=&#34;x7-280003&#34;&gt;Limitations of VMware DRS&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The major limitation of VMware DRS is scaling, which is due to several reasons. There is
a central controller for the cluster which monitors all the hosts and virtual machines.
In a cloud scale, where the hosts can grow to thousands in number and VMs
to tens of thousand, a central machine monitoring all of the components and
taking all the decisions is not possible. Apart from this, in making a decision, the
DRS considers all possible VM migrations. The time for running this algorithm
grows exponentially with the number of VMs and hence cannot scale. On top of
all this, the controller is a single point of failure for the whole cluster in this
design.
&lt;/p&gt;
&lt;p&gt;   Another limitation of VMware DRS is that it manages only CPU and memory
resources. Other resources like network bandwidth, and disk I/O, which can aﬀect the
performance of a VM,can also be considered.
&lt;a
id=&#34;x7-28001r28&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 class=&#34;sectionHead&#34;&gt;&lt;span class=&#34;titlemark&#34;&gt;2.4   &lt;/span&gt; &lt;a
href=&#34;main.html#QQ2-7-32&#34; id=&#34;x7-290004&#34;&gt;Other Works&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Sandpiper [&lt;a id=&#34;page.26&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-wood2009sandpiper&#34; &gt;17&lt;/a&gt;] is a system for automating the task of detecting hotspots and migrating VMs in
response to hotspots. For VM migration, Sandpiper takes three resources into consideration -
CPU, memory and network bandwidth. The empty volume of each host is calculated as
&lt;!--l. 110--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;y&lt;/mi&gt;&lt;mstyle
class=&#34;text&#34;&gt;&lt;mtext  &gt;_&lt;/mtext&gt;&lt;/mstyle&gt;&lt;mi
&gt;v&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;l&lt;/mi&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt; &lt;mrow &gt;&lt;mo
class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;c&lt;/mi&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow &gt;&lt;mo
class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;n&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow &gt;&lt;mo
class=&#34;MathClass-open&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;mo
class=&#34;MathClass-close&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;. It
calculates &lt;!--l. 110--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;v&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;l&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;/math&gt;
occupied by a VM as


&lt;!--tex4ht:inline--&gt;&lt;/p&gt;
&lt;!--l. 110--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;block&#34; &gt;
                    &lt;mi
&gt;v&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;l&lt;/mi&gt; &lt;mo
class=&#34;MathClass-rel&#34;&gt;=&lt;/mo&gt;     &lt;mfrac&gt;&lt;mrow
&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;
&lt;mrow
&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;c&lt;/mi&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;mi
&gt;u&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt;  &lt;mfrac&gt;&lt;mrow
&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;
&lt;mrow
&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;n&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;∗&lt;/mo&gt;   &lt;mfrac&gt;&lt;mrow
&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;
&lt;mrow
&gt;&lt;mn&gt;1&lt;/mn&gt; &lt;mo
class=&#34;MathClass-bin&#34;&gt;−&lt;/mo&gt; &lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;
&lt;/math&gt;
&lt;p&gt;. It then calculates volume to size ratio (VSR) of each VM, where size is a VMs
memory footprint. The VM with the maximum VSR from the host having the least
&lt;!--l. 110--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;y&lt;/mi&gt;&lt;mstyle
class=&#34;text&#34;&gt;&lt;mtext  &gt;_&lt;/mtext&gt;&lt;/mstyle&gt;&lt;mi
&gt;v&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;l&lt;/mi&gt;&lt;/math&gt; is migrated to the host
having the maximum &lt;!--l. 110--&gt;&lt;math
xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;  
display=&#34;inline&#34; &gt;&lt;mi
&gt;e&lt;/mi&gt;&lt;mi
&gt;m&lt;/mi&gt;&lt;mi
&gt;p&lt;/mi&gt;&lt;mi
&gt;t&lt;/mi&gt;&lt;mi
&gt;y&lt;/mi&gt;&lt;mstyle
class=&#34;text&#34;&gt;&lt;mtext  &gt;_&lt;/mtext&gt;&lt;/mstyle&gt;&lt;mi
&gt;v&lt;/mi&gt;&lt;mi
&gt;o&lt;/mi&gt;&lt;mi
&gt;l&lt;/mi&gt;&lt;/math&gt;.
Some of the problems and anomalies in this approach have been explored [&lt;a id=&#34;page.27&#34;&gt;&lt;/a&gt;&lt;a
href=&#34;mainli5.html#X0-mishra2011theory&#34; &gt;18&lt;/a&gt;].
&lt;/p&gt;
&lt;p&gt;   CloudScale [&lt;a
href=&#34;mainli5.html#X0-shen2011cloudscale&#34; &gt;19&lt;/a&gt;] uses long-term resource demand prediction models to predict the
resource demands of virtual machines in future based on the previous resource usage data.
It handle conﬂicts by proactive migration of virtual machines based on the predicted
demands. Tan et al. [&lt;a
href=&#34;mainli5.html#X0-tan2011exploiting&#34; &gt;20&lt;/a&gt;] propose a similar approach where they use a Principal
Component Analysis (PCA) based approach to predict the long-term resource usage
proﬁles of the VMs using the measurements obtained from a commercial data center.
They formulate the VM placement problem as a bin-packing problem and propose
to place VMs using variance reduction. But in doing so, they assume that the
resource usages of the VMs remains constant, which may not be the case in
reality.
&lt;/p&gt;
&lt;p&gt;   Vector Dot [&lt;a
href=&#34;mainli5.html#X0-singh2008server&#34; &gt;21&lt;/a&gt;] is a load balancing algorithm for handling multi-dimensional resource
constraints in a virtualized infrastructure. It expresses the normalized resource
requirements of machines as multi-dimensional vectors. It then uses the dot product
of the resource usage vector (RUV) of the host and the resource requirement
vector (RRV) of the guest to choose an appropriate host-VM mapping. To ensure
balanced usage of resources, the RRV of the guest should be complementary to the
RUV of the host. The anomalies with this approach have been discussed and
improvements have been proposed [&lt;a
href=&#34;mainli5.html#X0-mishra2011theory&#34; &gt;18&lt;/a&gt;]. But these studies do not take scaling
into consideration and are not distributed enough to handle the cloud scale.


They also do not consider the performance degradation that happens during live
migration.
&lt;a
id=&#34;Q1-7-33&#34;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h4 class=&#34;likesubsectionHead&#34;&gt;&lt;a
href=&#34;#x7-300004&#34; id=&#34;x7-300004&#34;&gt;Summary&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;In this chapter, we have discussed the autoballooning mechanism implemented in the Xen
hypervisor and how it is diﬀerent from the autoballooning in KVM. We have discussed
the techniques which VMware ESX implemens for memory management and distributed
resource scheduling. We have also explored some other important works in this area and
their drawbacks.


&lt;/p&gt;
&lt;!--l. 1--&gt;&lt;div class=&#34;crosslinks&#34;&gt;&lt;p class=&#34;noindent&#34;&gt;[&lt;a
href=&#34;mainch3.html&#34; &gt;next&lt;/a&gt;] [&lt;a
href=&#34;mainch1.html&#34; &gt;prev&lt;/a&gt;] [&lt;a
href=&#34;mainch1.html#tailmainch1.html&#34; &gt;prev-tail&lt;/a&gt;] [&lt;a
href=&#34;mainch2.html&#34; &gt;front&lt;/a&gt;] [&lt;a
href=&#34;main.html#mainch2.html&#34; &gt;up&lt;/a&gt;] &lt;/p&gt;&lt;/div&gt;
&lt;p&gt;   &lt;a
id=&#34;tailmainch2.html&#34;&gt;&lt;/a&gt;                  &lt;/p&gt;


</description>
    </item>
    
  </channel>
</rss>